{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from lib import model_device_io as io\n",
    "from lib import data_loader as dl\n",
    "from lib import models as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda:1\n",
      "model loaded from models/rev_best.pth\n"
     ]
    }
   ],
   "source": [
    "trainset = dl.HotelReservationData(root='data/train')\n",
    "testset = dl.HotelReservationData(root='data/test')\n",
    "train_loader = DataLoader(trainset, batch_size=4096, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=4096, shuffle=False, num_workers=0)\n",
    "device = io.getCudaDevice(cudaNum = 1, torchSeed = 123)\n",
    "model = md.Classifier(input_size = 258).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "io.loadModel('models/rev_best.pth', model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_epoch = 100, model_fn = \"rev_best.pth\", log_per_epoch = 4):\n",
    "    best_acc = test()\n",
    "    for epoch in range(train_epoch):\n",
    "        model.train()\n",
    "        for batch_idx, (data, _, rev) in enumerate(train_loader):\n",
    "            data, rev = data.to(device), rev.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, rev)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx+1) % max(1, int(len(train_loader)/log_per_epoch)) == 0:\n",
    "                print('Training Epoch: {:.2f}% ({}/{})\\tBatch: {:.2f}% ({}/{})\\tLoss: {:.6f}'.format(\n",
    "                      (epoch+1)*100./train_epoch, epoch+1, train_epoch, (batch_idx+1)*100./len(train_loader),\n",
    "                      batch_idx+1, len(train_loader), loss.item()))\n",
    "        acc = test()\n",
    "        if(best_acc < acc):\n",
    "            best_acc = acc\n",
    "            fn = os.path.join('models', model_fn)\n",
    "            io.saveModel(fn, model, optimizer)\n",
    "            \n",
    "            \n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    loss, correct = 0, 0\n",
    "    with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "        for data, _, rev in test_loader:\n",
    "            data, rev = data.to(device), rev.to(device)\n",
    "            output = model(data)\n",
    "            loss += F.cross_entropy(output, rev).item()*len(data) # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(rev.view_as(pred)).sum().item()\n",
    "            \n",
    "    loss /= len(test_loader.dataset)\n",
    "    acc = 1.*correct/len(test_loader.dataset)\n",
    "    print('***Validation Results***\\tLoss: {:.4f},\\tAccuracy: {:.2f}% ({}/{})\\n'.format(\n",
    "          loss, acc*100., correct, len(test_loader.dataset)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Validation Results***\tLoss: 11.5085,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 10.00% (1/10)\tBatch: 25.00% (5/20)\tLoss: 21.555044\n",
      "Training Epoch: 10.00% (1/10)\tBatch: 50.00% (10/20)\tLoss: 23.809071\n",
      "Training Epoch: 10.00% (1/10)\tBatch: 75.00% (15/20)\tLoss: 22.959814\n",
      "Training Epoch: 10.00% (1/10)\tBatch: 100.00% (20/20)\tLoss: 20.446157\n",
      "***Validation Results***\tLoss: 12.1257,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 20.00% (2/10)\tBatch: 25.00% (5/20)\tLoss: 22.276583\n",
      "Training Epoch: 20.00% (2/10)\tBatch: 50.00% (10/20)\tLoss: 19.837347\n",
      "Training Epoch: 20.00% (2/10)\tBatch: 75.00% (15/20)\tLoss: 24.895195\n",
      "Training Epoch: 20.00% (2/10)\tBatch: 100.00% (20/20)\tLoss: 22.160988\n",
      "***Validation Results***\tLoss: 12.2111,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 30.00% (3/10)\tBatch: 25.00% (5/20)\tLoss: 23.479626\n",
      "Training Epoch: 30.00% (3/10)\tBatch: 50.00% (10/20)\tLoss: 23.246603\n",
      "Training Epoch: 30.00% (3/10)\tBatch: 75.00% (15/20)\tLoss: 22.568569\n",
      "Training Epoch: 30.00% (3/10)\tBatch: 100.00% (20/20)\tLoss: 23.276617\n",
      "***Validation Results***\tLoss: 12.2054,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 40.00% (4/10)\tBatch: 25.00% (5/20)\tLoss: 21.978153\n",
      "Training Epoch: 40.00% (4/10)\tBatch: 50.00% (10/20)\tLoss: 21.740044\n",
      "Training Epoch: 40.00% (4/10)\tBatch: 75.00% (15/20)\tLoss: 22.838284\n",
      "Training Epoch: 40.00% (4/10)\tBatch: 100.00% (20/20)\tLoss: 24.238699\n",
      "***Validation Results***\tLoss: 12.1665,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 50.00% (5/10)\tBatch: 25.00% (5/20)\tLoss: 21.687849\n",
      "Training Epoch: 50.00% (5/10)\tBatch: 50.00% (10/20)\tLoss: 19.625301\n",
      "Training Epoch: 50.00% (5/10)\tBatch: 75.00% (15/20)\tLoss: 23.944664\n",
      "Training Epoch: 50.00% (5/10)\tBatch: 100.00% (20/20)\tLoss: 18.047190\n",
      "***Validation Results***\tLoss: 12.0957,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 60.00% (6/10)\tBatch: 25.00% (5/20)\tLoss: 21.310278\n",
      "Training Epoch: 60.00% (6/10)\tBatch: 50.00% (10/20)\tLoss: 29.609900\n",
      "Training Epoch: 60.00% (6/10)\tBatch: 75.00% (15/20)\tLoss: 21.467890\n",
      "Training Epoch: 60.00% (6/10)\tBatch: 100.00% (20/20)\tLoss: 21.754036\n",
      "***Validation Results***\tLoss: 11.9964,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 70.00% (7/10)\tBatch: 25.00% (5/20)\tLoss: 24.071367\n",
      "Training Epoch: 70.00% (7/10)\tBatch: 50.00% (10/20)\tLoss: 25.618607\n",
      "Training Epoch: 70.00% (7/10)\tBatch: 75.00% (15/20)\tLoss: 22.764277\n",
      "Training Epoch: 70.00% (7/10)\tBatch: 100.00% (20/20)\tLoss: 24.143690\n",
      "***Validation Results***\tLoss: 11.8735,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 80.00% (8/10)\tBatch: 25.00% (5/20)\tLoss: 19.952477\n",
      "Training Epoch: 80.00% (8/10)\tBatch: 50.00% (10/20)\tLoss: 23.300598\n",
      "Training Epoch: 80.00% (8/10)\tBatch: 75.00% (15/20)\tLoss: 20.733944\n",
      "Training Epoch: 80.00% (8/10)\tBatch: 100.00% (20/20)\tLoss: 20.599787\n",
      "***Validation Results***\tLoss: 11.7263,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 90.00% (9/10)\tBatch: 25.00% (5/20)\tLoss: 20.954779\n",
      "Training Epoch: 90.00% (9/10)\tBatch: 50.00% (10/20)\tLoss: 22.279680\n",
      "Training Epoch: 90.00% (9/10)\tBatch: 75.00% (15/20)\tLoss: 21.342436\n",
      "Training Epoch: 90.00% (9/10)\tBatch: 100.00% (20/20)\tLoss: 21.781752\n",
      "***Validation Results***\tLoss: 11.5631,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 100.00% (10/10)\tBatch: 25.00% (5/20)\tLoss: 22.767254\n",
      "Training Epoch: 100.00% (10/10)\tBatch: 50.00% (10/20)\tLoss: 22.210461\n",
      "Training Epoch: 100.00% (10/10)\tBatch: 75.00% (15/20)\tLoss: 21.642191\n",
      "Training Epoch: 100.00% (10/10)\tBatch: 100.00% (20/20)\tLoss: 19.321150\n",
      "***Validation Results***\tLoss: 11.3905,\tAccuracy: 64.30% (6430/10000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_epoch = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
