{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from lib import model_device_io as io\n",
    "from lib import data_loader as dl\n",
    "from lib import models as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda:1\n"
     ]
    }
   ],
   "source": [
    "trainset = dl.HotelReservationData(root='data/train')\n",
    "testset = dl.HotelReservationData(root='data/test')\n",
    "train_loader = DataLoader(trainset, batch_size=4096, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=4096, shuffle=False, num_workers=0)\n",
    "device = io.getCudaDevice(cudaNum = 1, torchSeed = 123)\n",
    "model = md.ClassifierLinear(input_size = 258).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "#io.loadModel('models/rev_best.pth', model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_epoch = 100, model_fn = \"rev_best.pth\", log_per_epoch = 3):\n",
    "    best_acc = test()\n",
    "    for epoch in range(train_epoch):\n",
    "        model.train()\n",
    "        for batch_idx, (data, _, rev) in enumerate(train_loader):\n",
    "            data, rev = data.to(device), rev.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, rev)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx+1) % max(1, int(len(train_loader)/log_per_epoch)) == 0:\n",
    "                print('Training Epoch: {:.2f}% ({}/{})\\tBatch: {:.2f}% ({}/{})\\tLoss: {:.6f}'.format(\n",
    "                      (epoch+1)*100./train_epoch, epoch+1, train_epoch, (batch_idx+1)*100./len(train_loader),\n",
    "                      batch_idx+1, len(train_loader), loss.item()))\n",
    "        acc = test()\n",
    "        if(best_acc < acc):\n",
    "            best_acc = acc\n",
    "            fn = os.path.join('models', model_fn)\n",
    "            io.saveModel(fn, model, optimizer)\n",
    "            \n",
    "            \n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    loss, correct = 0, 0\n",
    "    with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "        for data, _, rev in test_loader:\n",
    "            data, rev = data.to(device), rev.to(device)\n",
    "            output = model(data)\n",
    "            loss += F.cross_entropy(output, rev).item()*len(data) # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(rev.view_as(pred)).sum().item()\n",
    "            \n",
    "    loss /= len(test_loader.dataset)\n",
    "    acc = 1.*correct/len(test_loader.dataset)\n",
    "    print('***Validation Results***\\tLoss: {:.4f},\\tAccuracy: {:.2f}% ({}/{})\\n'.format(\n",
    "          loss, acc*100., correct, len(test_loader.dataset)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Validation Results***\tLoss: 2936.1087,\tAccuracy: 0.09% (9/10000)\n",
      "\n",
      "Training Epoch: 0.02% (1/5000)\tBatch: 100.00% (20/20)\tLoss: 3563.090088\n",
      "***Validation Results***\tLoss: 2635.3599,\tAccuracy: 0.19% (19/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.04% (2/5000)\tBatch: 100.00% (20/20)\tLoss: 3144.344727\n",
      "***Validation Results***\tLoss: 2331.7378,\tAccuracy: 0.30% (30/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.06% (3/5000)\tBatch: 100.00% (20/20)\tLoss: 2679.352783\n",
      "***Validation Results***\tLoss: 2026.1750,\tAccuracy: 0.39% (39/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.08% (4/5000)\tBatch: 100.00% (20/20)\tLoss: 2294.961670\n",
      "***Validation Results***\tLoss: 1719.6576,\tAccuracy: 0.55% (55/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.10% (5/5000)\tBatch: 100.00% (20/20)\tLoss: 1968.089600\n",
      "***Validation Results***\tLoss: 1414.0035,\tAccuracy: 0.88% (88/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.12% (6/5000)\tBatch: 100.00% (20/20)\tLoss: 1654.045166\n",
      "***Validation Results***\tLoss: 1109.7495,\tAccuracy: 1.26% (126/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.14% (7/5000)\tBatch: 100.00% (20/20)\tLoss: 1304.497925\n",
      "***Validation Results***\tLoss: 806.6851,\tAccuracy: 1.63% (163/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.16% (8/5000)\tBatch: 100.00% (20/20)\tLoss: 999.992676\n",
      "***Validation Results***\tLoss: 504.9091,\tAccuracy: 3.17% (317/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.18% (9/5000)\tBatch: 100.00% (20/20)\tLoss: 813.788025\n",
      "***Validation Results***\tLoss: 368.3771,\tAccuracy: 63.67% (6367/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.20% (10/5000)\tBatch: 100.00% (20/20)\tLoss: 703.761353\n",
      "***Validation Results***\tLoss: 364.4636,\tAccuracy: 63.64% (6364/10000)\n",
      "\n",
      "Training Epoch: 0.22% (11/5000)\tBatch: 100.00% (20/20)\tLoss: 579.594055\n",
      "***Validation Results***\tLoss: 357.5055,\tAccuracy: 63.60% (6360/10000)\n",
      "\n",
      "Training Epoch: 0.24% (12/5000)\tBatch: 100.00% (20/20)\tLoss: 537.192993\n",
      "***Validation Results***\tLoss: 348.5931,\tAccuracy: 63.49% (6349/10000)\n",
      "\n",
      "Training Epoch: 0.26% (13/5000)\tBatch: 100.00% (20/20)\tLoss: 559.934814\n",
      "***Validation Results***\tLoss: 339.1984,\tAccuracy: 63.38% (6338/10000)\n",
      "\n",
      "Training Epoch: 0.28% (14/5000)\tBatch: 100.00% (20/20)\tLoss: 611.785400\n",
      "***Validation Results***\tLoss: 330.3278,\tAccuracy: 63.26% (6326/10000)\n",
      "\n",
      "Training Epoch: 0.30% (15/5000)\tBatch: 100.00% (20/20)\tLoss: 680.693665\n",
      "***Validation Results***\tLoss: 321.8245,\tAccuracy: 63.19% (6319/10000)\n",
      "\n",
      "Training Epoch: 0.32% (16/5000)\tBatch: 100.00% (20/20)\tLoss: 728.092285\n",
      "***Validation Results***\tLoss: 313.4337,\tAccuracy: 63.02% (6302/10000)\n",
      "\n",
      "Training Epoch: 0.34% (17/5000)\tBatch: 100.00% (20/20)\tLoss: 791.211670\n",
      "***Validation Results***\tLoss: 304.9933,\tAccuracy: 63.05% (6305/10000)\n",
      "\n",
      "Training Epoch: 0.36% (18/5000)\tBatch: 100.00% (20/20)\tLoss: 756.537415\n",
      "***Validation Results***\tLoss: 296.3187,\tAccuracy: 63.05% (6305/10000)\n",
      "\n",
      "Training Epoch: 0.38% (19/5000)\tBatch: 100.00% (20/20)\tLoss: 891.557861\n",
      "***Validation Results***\tLoss: 287.2885,\tAccuracy: 62.98% (6298/10000)\n",
      "\n",
      "Training Epoch: 0.40% (20/5000)\tBatch: 100.00% (20/20)\tLoss: 836.217224\n",
      "***Validation Results***\tLoss: 277.8013,\tAccuracy: 62.80% (6280/10000)\n",
      "\n",
      "Training Epoch: 0.42% (21/5000)\tBatch: 100.00% (20/20)\tLoss: 933.254883\n",
      "***Validation Results***\tLoss: 267.8035,\tAccuracy: 62.66% (6266/10000)\n",
      "\n",
      "Training Epoch: 0.44% (22/5000)\tBatch: 100.00% (20/20)\tLoss: 942.783020\n",
      "***Validation Results***\tLoss: 257.2100,\tAccuracy: 62.39% (6239/10000)\n",
      "\n",
      "Training Epoch: 0.46% (23/5000)\tBatch: 100.00% (20/20)\tLoss: 1034.363403\n",
      "***Validation Results***\tLoss: 245.9498,\tAccuracy: 62.17% (6217/10000)\n",
      "\n",
      "Training Epoch: 0.48% (24/5000)\tBatch: 100.00% (20/20)\tLoss: 1040.746338\n",
      "***Validation Results***\tLoss: 233.9379,\tAccuracy: 62.16% (6216/10000)\n",
      "\n",
      "Training Epoch: 0.50% (25/5000)\tBatch: 100.00% (20/20)\tLoss: 1031.297363\n",
      "***Validation Results***\tLoss: 221.1284,\tAccuracy: 61.84% (6184/10000)\n",
      "\n",
      "Training Epoch: 0.52% (26/5000)\tBatch: 100.00% (20/20)\tLoss: 1077.974121\n",
      "***Validation Results***\tLoss: 207.5086,\tAccuracy: 61.86% (6186/10000)\n",
      "\n",
      "Training Epoch: 0.54% (27/5000)\tBatch: 100.00% (20/20)\tLoss: 1116.078735\n",
      "***Validation Results***\tLoss: 193.0639,\tAccuracy: 61.83% (6183/10000)\n",
      "\n",
      "Training Epoch: 0.56% (28/5000)\tBatch: 100.00% (20/20)\tLoss: 1158.390991\n",
      "***Validation Results***\tLoss: 177.7615,\tAccuracy: 61.53% (6153/10000)\n",
      "\n",
      "Training Epoch: 0.58% (29/5000)\tBatch: 100.00% (20/20)\tLoss: 1088.843018\n",
      "***Validation Results***\tLoss: 161.6027,\tAccuracy: 60.53% (6053/10000)\n",
      "\n",
      "Training Epoch: 0.60% (30/5000)\tBatch: 100.00% (20/20)\tLoss: 1096.833984\n",
      "***Validation Results***\tLoss: 144.8028,\tAccuracy: 59.32% (5932/10000)\n",
      "\n",
      "Training Epoch: 0.62% (31/5000)\tBatch: 100.00% (20/20)\tLoss: 1192.668457\n",
      "***Validation Results***\tLoss: 127.9655,\tAccuracy: 56.84% (5684/10000)\n",
      "\n",
      "Training Epoch: 0.64% (32/5000)\tBatch: 100.00% (20/20)\tLoss: 1238.063477\n",
      "***Validation Results***\tLoss: 112.6294,\tAccuracy: 54.14% (5414/10000)\n",
      "\n",
      "Training Epoch: 0.66% (33/5000)\tBatch: 100.00% (20/20)\tLoss: 1295.106201\n",
      "***Validation Results***\tLoss: 103.3901,\tAccuracy: 49.66% (4966/10000)\n",
      "\n",
      "Training Epoch: 0.68% (34/5000)\tBatch: 100.00% (20/20)\tLoss: 1239.500488\n",
      "***Validation Results***\tLoss: 116.7694,\tAccuracy: 36.70% (3670/10000)\n",
      "\n",
      "Training Epoch: 0.70% (35/5000)\tBatch: 100.00% (20/20)\tLoss: 1263.835938\n",
      "***Validation Results***\tLoss: 154.2609,\tAccuracy: 34.47% (3447/10000)\n",
      "\n",
      "Training Epoch: 0.72% (36/5000)\tBatch: 100.00% (20/20)\tLoss: 1258.919067\n",
      "***Validation Results***\tLoss: 180.7855,\tAccuracy: 34.47% (3447/10000)\n",
      "\n",
      "Training Epoch: 0.74% (37/5000)\tBatch: 100.00% (20/20)\tLoss: 1233.470825\n",
      "***Validation Results***\tLoss: 194.1617,\tAccuracy: 34.47% (3447/10000)\n",
      "\n",
      "Training Epoch: 0.76% (38/5000)\tBatch: 100.00% (20/20)\tLoss: 1294.174805\n",
      "***Validation Results***\tLoss: 193.7759,\tAccuracy: 34.47% (3447/10000)\n",
      "\n",
      "Training Epoch: 0.78% (39/5000)\tBatch: 100.00% (20/20)\tLoss: 1276.611328\n",
      "***Validation Results***\tLoss: 179.1884,\tAccuracy: 34.47% (3447/10000)\n",
      "\n",
      "Training Epoch: 0.80% (40/5000)\tBatch: 100.00% (20/20)\tLoss: 1259.542358\n",
      "***Validation Results***\tLoss: 150.0029,\tAccuracy: 34.57% (3457/10000)\n",
      "\n",
      "Training Epoch: 0.82% (41/5000)\tBatch: 100.00% (20/20)\tLoss: 1201.067017\n",
      "***Validation Results***\tLoss: 110.3380,\tAccuracy: 43.81% (4381/10000)\n",
      "\n",
      "Training Epoch: 0.84% (42/5000)\tBatch: 100.00% (20/20)\tLoss: 1198.625488\n",
      "***Validation Results***\tLoss: 110.8234,\tAccuracy: 54.52% (5452/10000)\n",
      "\n",
      "Training Epoch: 0.86% (43/5000)\tBatch: 100.00% (20/20)\tLoss: 1205.039795\n",
      "***Validation Results***\tLoss: 134.9326,\tAccuracy: 59.72% (5972/10000)\n",
      "\n",
      "Training Epoch: 0.88% (44/5000)\tBatch: 100.00% (20/20)\tLoss: 1121.689331\n",
      "***Validation Results***\tLoss: 163.2754,\tAccuracy: 62.13% (6213/10000)\n",
      "\n",
      "Training Epoch: 0.90% (45/5000)\tBatch: 100.00% (20/20)\tLoss: 1059.859497\n",
      "***Validation Results***\tLoss: 191.3350,\tAccuracy: 62.71% (6271/10000)\n",
      "\n",
      "Training Epoch: 0.92% (46/5000)\tBatch: 100.00% (20/20)\tLoss: 1048.678955\n",
      "***Validation Results***\tLoss: 218.1906,\tAccuracy: 63.42% (6342/10000)\n",
      "\n",
      "Training Epoch: 0.94% (47/5000)\tBatch: 100.00% (20/20)\tLoss: 1084.073120\n",
      "***Validation Results***\tLoss: 243.3207,\tAccuracy: 63.78% (6378/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.96% (48/5000)\tBatch: 100.00% (20/20)\tLoss: 1068.297974\n",
      "***Validation Results***\tLoss: 266.3719,\tAccuracy: 64.16% (6416/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 0.98% (49/5000)\tBatch: 100.00% (20/20)\tLoss: 1026.142700\n",
      "***Validation Results***\tLoss: 287.0881,\tAccuracy: 64.47% (6447/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.00% (50/5000)\tBatch: 100.00% (20/20)\tLoss: 954.141602\n",
      "***Validation Results***\tLoss: 305.2692,\tAccuracy: 64.56% (6456/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.02% (51/5000)\tBatch: 100.00% (20/20)\tLoss: 949.610352\n",
      "***Validation Results***\tLoss: 320.7167,\tAccuracy: 64.68% (6468/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.04% (52/5000)\tBatch: 100.00% (20/20)\tLoss: 909.427307\n",
      "***Validation Results***\tLoss: 333.4120,\tAccuracy: 64.65% (6465/10000)\n",
      "\n",
      "Training Epoch: 1.06% (53/5000)\tBatch: 100.00% (20/20)\tLoss: 810.384766\n",
      "***Validation Results***\tLoss: 343.4090,\tAccuracy: 64.70% (6470/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.08% (54/5000)\tBatch: 100.00% (20/20)\tLoss: 728.640625\n",
      "***Validation Results***\tLoss: 350.7477,\tAccuracy: 64.81% (6481/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.10% (55/5000)\tBatch: 100.00% (20/20)\tLoss: 667.780823\n",
      "***Validation Results***\tLoss: 355.4739,\tAccuracy: 64.78% (6478/10000)\n",
      "\n",
      "Training Epoch: 1.12% (56/5000)\tBatch: 100.00% (20/20)\tLoss: 614.998291\n",
      "***Validation Results***\tLoss: 357.7433,\tAccuracy: 64.76% (6476/10000)\n",
      "\n",
      "Training Epoch: 1.14% (57/5000)\tBatch: 100.00% (20/20)\tLoss: 549.682861\n",
      "***Validation Results***\tLoss: 357.7446,\tAccuracy: 64.84% (6484/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.16% (58/5000)\tBatch: 100.00% (20/20)\tLoss: 510.012634\n",
      "***Validation Results***\tLoss: 355.6911,\tAccuracy: 64.85% (6485/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.18% (59/5000)\tBatch: 100.00% (20/20)\tLoss: 420.546936\n",
      "***Validation Results***\tLoss: 351.8085,\tAccuracy: 64.85% (6485/10000)\n",
      "\n",
      "Training Epoch: 1.20% (60/5000)\tBatch: 100.00% (20/20)\tLoss: 348.268860\n",
      "***Validation Results***\tLoss: 346.2560,\tAccuracy: 64.88% (6488/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.22% (61/5000)\tBatch: 100.00% (20/20)\tLoss: 329.046173\n",
      "***Validation Results***\tLoss: 338.0672,\tAccuracy: 64.89% (6489/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.24% (62/5000)\tBatch: 100.00% (20/20)\tLoss: 301.963470\n",
      "***Validation Results***\tLoss: 325.6045,\tAccuracy: 64.96% (6496/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.26% (63/5000)\tBatch: 100.00% (20/20)\tLoss: 303.914856\n",
      "***Validation Results***\tLoss: 308.7714,\tAccuracy: 65.02% (6502/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.28% (64/5000)\tBatch: 100.00% (20/20)\tLoss: 280.458435\n",
      "***Validation Results***\tLoss: 287.8654,\tAccuracy: 65.10% (6510/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.30% (65/5000)\tBatch: 100.00% (20/20)\tLoss: 344.400482\n",
      "***Validation Results***\tLoss: 263.4424,\tAccuracy: 65.16% (6516/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.32% (66/5000)\tBatch: 100.00% (20/20)\tLoss: 437.562683\n",
      "***Validation Results***\tLoss: 239.1678,\tAccuracy: 65.27% (6527/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.34% (67/5000)\tBatch: 100.00% (20/20)\tLoss: 589.701904\n",
      "***Validation Results***\tLoss: 217.6984,\tAccuracy: 65.38% (6538/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.36% (68/5000)\tBatch: 100.00% (20/20)\tLoss: 639.413208\n",
      "***Validation Results***\tLoss: 199.0163,\tAccuracy: 65.61% (6561/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.38% (69/5000)\tBatch: 100.00% (20/20)\tLoss: 799.504028\n",
      "***Validation Results***\tLoss: 182.8674,\tAccuracy: 65.84% (6584/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.40% (70/5000)\tBatch: 100.00% (20/20)\tLoss: 877.842346\n",
      "***Validation Results***\tLoss: 169.0642,\tAccuracy: 65.94% (6594/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.42% (71/5000)\tBatch: 100.00% (20/20)\tLoss: 997.392822\n",
      "***Validation Results***\tLoss: 157.3291,\tAccuracy: 66.05% (6605/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.44% (72/5000)\tBatch: 100.00% (20/20)\tLoss: 1042.489502\n",
      "***Validation Results***\tLoss: 147.5537,\tAccuracy: 66.00% (6600/10000)\n",
      "\n",
      "Training Epoch: 1.46% (73/5000)\tBatch: 100.00% (20/20)\tLoss: 1122.453125\n",
      "***Validation Results***\tLoss: 139.6242,\tAccuracy: 65.89% (6589/10000)\n",
      "\n",
      "Training Epoch: 1.48% (74/5000)\tBatch: 100.00% (20/20)\tLoss: 1160.575684\n",
      "***Validation Results***\tLoss: 133.4947,\tAccuracy: 65.80% (6580/10000)\n",
      "\n",
      "Training Epoch: 1.50% (75/5000)\tBatch: 100.00% (20/20)\tLoss: 1196.101196\n",
      "***Validation Results***\tLoss: 129.1435,\tAccuracy: 65.92% (6592/10000)\n",
      "\n",
      "Training Epoch: 1.52% (76/5000)\tBatch: 100.00% (20/20)\tLoss: 1188.647705\n",
      "***Validation Results***\tLoss: 126.6072,\tAccuracy: 66.08% (6608/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.54% (77/5000)\tBatch: 100.00% (20/20)\tLoss: 1169.557861\n",
      "***Validation Results***\tLoss: 125.9625,\tAccuracy: 66.17% (6617/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.56% (78/5000)\tBatch: 100.00% (20/20)\tLoss: 1284.328735\n",
      "***Validation Results***\tLoss: 127.2761,\tAccuracy: 66.47% (6647/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.58% (79/5000)\tBatch: 100.00% (20/20)\tLoss: 1210.503540\n",
      "***Validation Results***\tLoss: 130.6041,\tAccuracy: 66.59% (6659/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 1.60% (80/5000)\tBatch: 100.00% (20/20)\tLoss: 1175.705933\n",
      "***Validation Results***\tLoss: 135.9489,\tAccuracy: 66.56% (6656/10000)\n",
      "\n",
      "Training Epoch: 1.62% (81/5000)\tBatch: 100.00% (20/20)\tLoss: 1157.739502\n",
      "***Validation Results***\tLoss: 143.3325,\tAccuracy: 66.57% (6657/10000)\n",
      "\n",
      "Training Epoch: 1.64% (82/5000)\tBatch: 100.00% (20/20)\tLoss: 1162.829224\n",
      "***Validation Results***\tLoss: 152.8049,\tAccuracy: 66.56% (6656/10000)\n",
      "\n",
      "Training Epoch: 1.66% (83/5000)\tBatch: 100.00% (20/20)\tLoss: 1077.715454\n",
      "***Validation Results***\tLoss: 164.3703,\tAccuracy: 66.54% (6654/10000)\n",
      "\n",
      "Training Epoch: 1.68% (84/5000)\tBatch: 100.00% (20/20)\tLoss: 1027.054932\n",
      "***Validation Results***\tLoss: 177.9154,\tAccuracy: 66.44% (6644/10000)\n",
      "\n",
      "Training Epoch: 1.70% (85/5000)\tBatch: 100.00% (20/20)\tLoss: 925.341858\n",
      "***Validation Results***\tLoss: 193.3540,\tAccuracy: 66.01% (6601/10000)\n",
      "\n",
      "Training Epoch: 1.72% (86/5000)\tBatch: 100.00% (20/20)\tLoss: 863.698853\n",
      "***Validation Results***\tLoss: 210.5695,\tAccuracy: 65.62% (6562/10000)\n",
      "\n",
      "Training Epoch: 1.74% (87/5000)\tBatch: 100.00% (20/20)\tLoss: 734.755981\n",
      "***Validation Results***\tLoss: 229.3165,\tAccuracy: 65.39% (6539/10000)\n",
      "\n",
      "Training Epoch: 1.76% (88/5000)\tBatch: 100.00% (20/20)\tLoss: 632.253845\n",
      "***Validation Results***\tLoss: 249.3085,\tAccuracy: 65.09% (6509/10000)\n",
      "\n",
      "Training Epoch: 1.78% (89/5000)\tBatch: 100.00% (20/20)\tLoss: 535.039368\n",
      "***Validation Results***\tLoss: 270.2801,\tAccuracy: 64.83% (6483/10000)\n",
      "\n",
      "Training Epoch: 1.80% (90/5000)\tBatch: 100.00% (20/20)\tLoss: 330.956421\n",
      "***Validation Results***\tLoss: 291.8961,\tAccuracy: 64.59% (6459/10000)\n",
      "\n",
      "Training Epoch: 1.82% (91/5000)\tBatch: 100.00% (20/20)\tLoss: 291.602112\n",
      "***Validation Results***\tLoss: 313.5838,\tAccuracy: 64.38% (6438/10000)\n",
      "\n",
      "Training Epoch: 1.84% (92/5000)\tBatch: 100.00% (20/20)\tLoss: 305.709381\n",
      "***Validation Results***\tLoss: 331.9937,\tAccuracy: 64.37% (6437/10000)\n",
      "\n",
      "Training Epoch: 1.86% (93/5000)\tBatch: 100.00% (20/20)\tLoss: 339.704956\n",
      "***Validation Results***\tLoss: 344.4430,\tAccuracy: 64.32% (6432/10000)\n",
      "\n",
      "Training Epoch: 1.88% (94/5000)\tBatch: 100.00% (20/20)\tLoss: 314.943481\n",
      "***Validation Results***\tLoss: 350.8955,\tAccuracy: 64.33% (6433/10000)\n",
      "\n",
      "Training Epoch: 1.90% (95/5000)\tBatch: 100.00% (20/20)\tLoss: 335.958008\n",
      "***Validation Results***\tLoss: 351.7696,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 1.92% (96/5000)\tBatch: 100.00% (20/20)\tLoss: 375.552399\n",
      "***Validation Results***\tLoss: 348.0257,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 1.94% (97/5000)\tBatch: 100.00% (20/20)\tLoss: 415.100189\n",
      "***Validation Results***\tLoss: 342.2990,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 1.96% (98/5000)\tBatch: 100.00% (20/20)\tLoss: 474.325439\n",
      "***Validation Results***\tLoss: 335.6583,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 1.98% (99/5000)\tBatch: 100.00% (20/20)\tLoss: 595.288513\n",
      "***Validation Results***\tLoss: 328.2390,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.00% (100/5000)\tBatch: 100.00% (20/20)\tLoss: 654.143250\n",
      "***Validation Results***\tLoss: 320.0063,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.02% (101/5000)\tBatch: 100.00% (20/20)\tLoss: 704.185120\n",
      "***Validation Results***\tLoss: 310.9450,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.04% (102/5000)\tBatch: 100.00% (20/20)\tLoss: 765.976257\n",
      "***Validation Results***\tLoss: 301.0136,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.06% (103/5000)\tBatch: 100.00% (20/20)\tLoss: 779.231445\n",
      "***Validation Results***\tLoss: 290.1310,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.08% (104/5000)\tBatch: 100.00% (20/20)\tLoss: 838.987000\n",
      "***Validation Results***\tLoss: 278.3029,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.10% (105/5000)\tBatch: 100.00% (20/20)\tLoss: 922.373901\n",
      "***Validation Results***\tLoss: 265.4603,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.12% (106/5000)\tBatch: 100.00% (20/20)\tLoss: 997.095642\n",
      "***Validation Results***\tLoss: 251.5631,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.14% (107/5000)\tBatch: 100.00% (20/20)\tLoss: 990.420227\n",
      "***Validation Results***\tLoss: 236.6064,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.16% (108/5000)\tBatch: 100.00% (20/20)\tLoss: 984.251465\n",
      "***Validation Results***\tLoss: 220.5249,\tAccuracy: 64.35% (6435/10000)\n",
      "\n",
      "Training Epoch: 2.18% (109/5000)\tBatch: 100.00% (20/20)\tLoss: 970.803528\n",
      "***Validation Results***\tLoss: 203.3359,\tAccuracy: 66.03% (6603/10000)\n",
      "\n",
      "Training Epoch: 2.20% (110/5000)\tBatch: 100.00% (20/20)\tLoss: 1067.554199\n",
      "***Validation Results***\tLoss: 185.7261,\tAccuracy: 67.82% (6782/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 2.22% (111/5000)\tBatch: 100.00% (20/20)\tLoss: 1123.104004\n",
      "***Validation Results***\tLoss: 169.8185,\tAccuracy: 68.98% (6898/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 2.24% (112/5000)\tBatch: 100.00% (20/20)\tLoss: 1070.314697\n",
      "***Validation Results***\tLoss: 164.9839,\tAccuracy: 63.71% (6371/10000)\n",
      "\n",
      "Training Epoch: 2.26% (113/5000)\tBatch: 100.00% (20/20)\tLoss: 1109.847900\n",
      "***Validation Results***\tLoss: 185.2934,\tAccuracy: 53.61% (5361/10000)\n",
      "\n",
      "Training Epoch: 2.28% (114/5000)\tBatch: 100.00% (20/20)\tLoss: 1159.395020\n",
      "***Validation Results***\tLoss: 211.0758,\tAccuracy: 50.44% (5044/10000)\n",
      "\n",
      "Training Epoch: 2.30% (115/5000)\tBatch: 100.00% (20/20)\tLoss: 1187.418091\n",
      "***Validation Results***\tLoss: 231.9267,\tAccuracy: 48.80% (4880/10000)\n",
      "\n",
      "Training Epoch: 2.32% (116/5000)\tBatch: 100.00% (20/20)\tLoss: 1185.513794\n",
      "***Validation Results***\tLoss: 244.6367,\tAccuracy: 47.58% (4758/10000)\n",
      "\n",
      "Training Epoch: 2.34% (117/5000)\tBatch: 100.00% (20/20)\tLoss: 1280.444458\n",
      "***Validation Results***\tLoss: 248.0182,\tAccuracy: 47.59% (4759/10000)\n",
      "\n",
      "Training Epoch: 2.36% (118/5000)\tBatch: 100.00% (20/20)\tLoss: 1154.236572\n",
      "***Validation Results***\tLoss: 241.7296,\tAccuracy: 48.56% (4856/10000)\n",
      "\n",
      "Training Epoch: 2.38% (119/5000)\tBatch: 100.00% (20/20)\tLoss: 1202.492432\n",
      "***Validation Results***\tLoss: 226.3218,\tAccuracy: 49.95% (4995/10000)\n",
      "\n",
      "Training Epoch: 2.40% (120/5000)\tBatch: 100.00% (20/20)\tLoss: 1280.934692\n",
      "***Validation Results***\tLoss: 203.8531,\tAccuracy: 52.27% (5227/10000)\n",
      "\n",
      "Training Epoch: 2.42% (121/5000)\tBatch: 100.00% (20/20)\tLoss: 1155.258789\n",
      "***Validation Results***\tLoss: 181.5901,\tAccuracy: 60.63% (6063/10000)\n",
      "\n",
      "Training Epoch: 2.44% (122/5000)\tBatch: 100.00% (20/20)\tLoss: 1085.340088\n",
      "***Validation Results***\tLoss: 183.6268,\tAccuracy: 68.25% (6825/10000)\n",
      "\n",
      "Training Epoch: 2.46% (123/5000)\tBatch: 100.00% (20/20)\tLoss: 1246.758179\n",
      "***Validation Results***\tLoss: 206.8970,\tAccuracy: 66.99% (6699/10000)\n",
      "\n",
      "Training Epoch: 2.48% (124/5000)\tBatch: 100.00% (20/20)\tLoss: 1224.193115\n",
      "***Validation Results***\tLoss: 234.1694,\tAccuracy: 64.45% (6445/10000)\n",
      "\n",
      "Training Epoch: 2.50% (125/5000)\tBatch: 100.00% (20/20)\tLoss: 1144.145264\n",
      "***Validation Results***\tLoss: 261.1754,\tAccuracy: 64.35% (6435/10000)\n",
      "\n",
      "Training Epoch: 2.52% (126/5000)\tBatch: 100.00% (20/20)\tLoss: 1211.827271\n",
      "***Validation Results***\tLoss: 286.7383,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.54% (127/5000)\tBatch: 100.00% (20/20)\tLoss: 1090.951416\n",
      "***Validation Results***\tLoss: 310.6709,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.56% (128/5000)\tBatch: 100.00% (20/20)\tLoss: 1054.108765\n",
      "***Validation Results***\tLoss: 332.8510,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.58% (129/5000)\tBatch: 100.00% (20/20)\tLoss: 1063.334473\n",
      "***Validation Results***\tLoss: 353.1703,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.60% (130/5000)\tBatch: 100.00% (20/20)\tLoss: 1035.193848\n",
      "***Validation Results***\tLoss: 371.5217,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.62% (131/5000)\tBatch: 100.00% (20/20)\tLoss: 1071.201538\n",
      "***Validation Results***\tLoss: 387.8510,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.64% (132/5000)\tBatch: 100.00% (20/20)\tLoss: 1041.400146\n",
      "***Validation Results***\tLoss: 402.1326,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.66% (133/5000)\tBatch: 100.00% (20/20)\tLoss: 1002.622742\n",
      "***Validation Results***\tLoss: 414.3108,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.68% (134/5000)\tBatch: 100.00% (20/20)\tLoss: 933.953735\n",
      "***Validation Results***\tLoss: 424.3463,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.70% (135/5000)\tBatch: 100.00% (20/20)\tLoss: 786.797058\n",
      "***Validation Results***\tLoss: 432.2610,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.72% (136/5000)\tBatch: 100.00% (20/20)\tLoss: 826.647583\n",
      "***Validation Results***\tLoss: 438.0430,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.74% (137/5000)\tBatch: 100.00% (20/20)\tLoss: 776.746399\n",
      "***Validation Results***\tLoss: 441.7119,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.76% (138/5000)\tBatch: 100.00% (20/20)\tLoss: 705.868164\n",
      "***Validation Results***\tLoss: 443.3826,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.78% (139/5000)\tBatch: 100.00% (20/20)\tLoss: 635.786621\n",
      "***Validation Results***\tLoss: 443.0375,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.80% (140/5000)\tBatch: 100.00% (20/20)\tLoss: 562.966125\n",
      "***Validation Results***\tLoss: 440.7306,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.82% (141/5000)\tBatch: 100.00% (20/20)\tLoss: 519.487915\n",
      "***Validation Results***\tLoss: 436.6257,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.84% (142/5000)\tBatch: 100.00% (20/20)\tLoss: 506.299927\n",
      "***Validation Results***\tLoss: 430.7413,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.86% (143/5000)\tBatch: 100.00% (20/20)\tLoss: 387.258026\n",
      "***Validation Results***\tLoss: 422.9837,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.88% (144/5000)\tBatch: 100.00% (20/20)\tLoss: 412.769226\n",
      "***Validation Results***\tLoss: 412.2991,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.90% (145/5000)\tBatch: 100.00% (20/20)\tLoss: 344.380707\n",
      "***Validation Results***\tLoss: 397.0719,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.92% (146/5000)\tBatch: 100.00% (20/20)\tLoss: 361.769470\n",
      "***Validation Results***\tLoss: 377.0867,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.94% (147/5000)\tBatch: 100.00% (20/20)\tLoss: 382.727478\n",
      "***Validation Results***\tLoss: 352.5769,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.96% (148/5000)\tBatch: 100.00% (20/20)\tLoss: 385.819672\n",
      "***Validation Results***\tLoss: 324.0596,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 2.98% (149/5000)\tBatch: 100.00% (20/20)\tLoss: 513.605957\n",
      "***Validation Results***\tLoss: 294.8303,\tAccuracy: 64.30% (6430/10000)\n",
      "\n",
      "Training Epoch: 3.00% (150/5000)\tBatch: 100.00% (20/20)\tLoss: 629.454346\n",
      "***Validation Results***\tLoss: 267.6504,\tAccuracy: 64.35% (6435/10000)\n",
      "\n",
      "Training Epoch: 3.02% (151/5000)\tBatch: 100.00% (20/20)\tLoss: 749.159180\n",
      "***Validation Results***\tLoss: 242.8007,\tAccuracy: 64.45% (6445/10000)\n",
      "\n",
      "Training Epoch: 3.04% (152/5000)\tBatch: 100.00% (20/20)\tLoss: 775.075134\n",
      "***Validation Results***\tLoss: 220.4932,\tAccuracy: 65.59% (6559/10000)\n",
      "\n",
      "Training Epoch: 3.06% (153/5000)\tBatch: 100.00% (20/20)\tLoss: 935.992310\n",
      "***Validation Results***\tLoss: 201.2246,\tAccuracy: 67.33% (6733/10000)\n",
      "\n",
      "Training Epoch: 3.08% (154/5000)\tBatch: 100.00% (20/20)\tLoss: 1007.709717\n",
      "***Validation Results***\tLoss: 185.5772,\tAccuracy: 68.02% (6802/10000)\n",
      "\n",
      "Training Epoch: 3.10% (155/5000)\tBatch: 100.00% (20/20)\tLoss: 1056.510010\n",
      "***Validation Results***\tLoss: 174.5025,\tAccuracy: 68.33% (6833/10000)\n",
      "\n",
      "Training Epoch: 3.12% (156/5000)\tBatch: 100.00% (20/20)\tLoss: 1051.777100\n",
      "***Validation Results***\tLoss: 170.9169,\tAccuracy: 64.91% (6491/10000)\n",
      "\n",
      "Training Epoch: 3.14% (157/5000)\tBatch: 100.00% (20/20)\tLoss: 1152.225098\n",
      "***Validation Results***\tLoss: 177.1185,\tAccuracy: 60.62% (6062/10000)\n",
      "\n",
      "Training Epoch: 3.16% (158/5000)\tBatch: 100.00% (20/20)\tLoss: 1247.557861\n",
      "***Validation Results***\tLoss: 188.2274,\tAccuracy: 56.48% (5648/10000)\n",
      "\n",
      "Training Epoch: 3.18% (159/5000)\tBatch: 100.00% (20/20)\tLoss: 1215.054565\n",
      "***Validation Results***\tLoss: 200.6959,\tAccuracy: 53.66% (5366/10000)\n",
      "\n",
      "Training Epoch: 3.20% (160/5000)\tBatch: 100.00% (20/20)\tLoss: 1198.838135\n",
      "***Validation Results***\tLoss: 212.5964,\tAccuracy: 52.11% (5211/10000)\n",
      "\n",
      "Training Epoch: 3.22% (161/5000)\tBatch: 100.00% (20/20)\tLoss: 1224.476807\n",
      "***Validation Results***\tLoss: 223.0004,\tAccuracy: 51.42% (5142/10000)\n",
      "\n",
      "Training Epoch: 3.24% (162/5000)\tBatch: 100.00% (20/20)\tLoss: 1193.201294\n",
      "***Validation Results***\tLoss: 231.3036,\tAccuracy: 50.92% (5092/10000)\n",
      "\n",
      "Training Epoch: 3.26% (163/5000)\tBatch: 100.00% (20/20)\tLoss: 1192.582764\n",
      "***Validation Results***\tLoss: 237.1804,\tAccuracy: 50.50% (5050/10000)\n",
      "\n",
      "Training Epoch: 3.28% (164/5000)\tBatch: 100.00% (20/20)\tLoss: 1191.853638\n",
      "***Validation Results***\tLoss: 240.3643,\tAccuracy: 50.47% (5047/10000)\n",
      "\n",
      "Training Epoch: 3.30% (165/5000)\tBatch: 100.00% (20/20)\tLoss: 1091.078247\n",
      "***Validation Results***\tLoss: 240.8041,\tAccuracy: 50.52% (5052/10000)\n",
      "\n",
      "Training Epoch: 3.32% (166/5000)\tBatch: 100.00% (20/20)\tLoss: 1041.880981\n",
      "***Validation Results***\tLoss: 238.5550,\tAccuracy: 50.86% (5086/10000)\n",
      "\n",
      "Training Epoch: 3.34% (167/5000)\tBatch: 100.00% (20/20)\tLoss: 998.529785\n",
      "***Validation Results***\tLoss: 233.6694,\tAccuracy: 51.40% (5140/10000)\n",
      "\n",
      "Training Epoch: 3.36% (168/5000)\tBatch: 100.00% (20/20)\tLoss: 937.438660\n",
      "***Validation Results***\tLoss: 226.5553,\tAccuracy: 51.83% (5183/10000)\n",
      "\n",
      "Training Epoch: 3.38% (169/5000)\tBatch: 100.00% (20/20)\tLoss: 771.404663\n",
      "***Validation Results***\tLoss: 217.7886,\tAccuracy: 53.28% (5328/10000)\n",
      "\n",
      "Training Epoch: 3.40% (170/5000)\tBatch: 100.00% (20/20)\tLoss: 710.283875\n",
      "***Validation Results***\tLoss: 208.2570,\tAccuracy: 55.65% (5565/10000)\n",
      "\n",
      "Training Epoch: 3.42% (171/5000)\tBatch: 100.00% (20/20)\tLoss: 634.697327\n",
      "***Validation Results***\tLoss: 199.4042,\tAccuracy: 58.98% (5898/10000)\n",
      "\n",
      "Training Epoch: 3.44% (172/5000)\tBatch: 100.00% (20/20)\tLoss: 468.915253\n",
      "***Validation Results***\tLoss: 193.6300,\tAccuracy: 62.52% (6252/10000)\n",
      "\n",
      "Training Epoch: 3.46% (173/5000)\tBatch: 100.00% (20/20)\tLoss: 283.601410\n",
      "***Validation Results***\tLoss: 193.5312,\tAccuracy: 67.52% (6752/10000)\n",
      "\n",
      "Training Epoch: 3.48% (174/5000)\tBatch: 100.00% (20/20)\tLoss: 152.719147\n",
      "***Validation Results***\tLoss: 201.1248,\tAccuracy: 68.70% (6870/10000)\n",
      "\n",
      "Training Epoch: 3.50% (175/5000)\tBatch: 100.00% (20/20)\tLoss: 169.466782\n",
      "***Validation Results***\tLoss: 211.7629,\tAccuracy: 68.53% (6853/10000)\n",
      "\n",
      "Training Epoch: 3.52% (176/5000)\tBatch: 100.00% (20/20)\tLoss: 280.931610\n",
      "***Validation Results***\tLoss: 221.9387,\tAccuracy: 68.12% (6812/10000)\n",
      "\n",
      "Training Epoch: 3.54% (177/5000)\tBatch: 100.00% (20/20)\tLoss: 319.190979\n",
      "***Validation Results***\tLoss: 231.2756,\tAccuracy: 67.65% (6765/10000)\n",
      "\n",
      "Training Epoch: 3.56% (178/5000)\tBatch: 100.00% (20/20)\tLoss: 419.732910\n",
      "***Validation Results***\tLoss: 239.9027,\tAccuracy: 67.44% (6744/10000)\n",
      "\n",
      "Training Epoch: 3.58% (179/5000)\tBatch: 100.00% (20/20)\tLoss: 501.994812\n",
      "***Validation Results***\tLoss: 247.6502,\tAccuracy: 67.21% (6721/10000)\n",
      "\n",
      "Training Epoch: 3.60% (180/5000)\tBatch: 100.00% (20/20)\tLoss: 559.708618\n",
      "***Validation Results***\tLoss: 254.5279,\tAccuracy: 67.15% (6715/10000)\n",
      "\n",
      "Training Epoch: 3.62% (181/5000)\tBatch: 100.00% (20/20)\tLoss: 648.357910\n",
      "***Validation Results***\tLoss: 260.4980,\tAccuracy: 66.91% (6691/10000)\n",
      "\n",
      "Training Epoch: 3.64% (182/5000)\tBatch: 100.00% (20/20)\tLoss: 694.240295\n",
      "***Validation Results***\tLoss: 265.5536,\tAccuracy: 66.75% (6675/10000)\n",
      "\n",
      "Training Epoch: 3.66% (183/5000)\tBatch: 100.00% (20/20)\tLoss: 654.759155\n",
      "***Validation Results***\tLoss: 269.7337,\tAccuracy: 66.67% (6667/10000)\n",
      "\n",
      "Training Epoch: 3.68% (184/5000)\tBatch: 100.00% (20/20)\tLoss: 727.554810\n",
      "***Validation Results***\tLoss: 273.0931,\tAccuracy: 66.66% (6666/10000)\n",
      "\n",
      "Training Epoch: 3.70% (185/5000)\tBatch: 100.00% (20/20)\tLoss: 753.350891\n",
      "***Validation Results***\tLoss: 275.6567,\tAccuracy: 66.66% (6666/10000)\n",
      "\n",
      "Training Epoch: 3.72% (186/5000)\tBatch: 100.00% (20/20)\tLoss: 837.866211\n",
      "***Validation Results***\tLoss: 277.4223,\tAccuracy: 66.71% (6671/10000)\n",
      "\n",
      "Training Epoch: 3.74% (187/5000)\tBatch: 100.00% (20/20)\tLoss: 909.884399\n",
      "***Validation Results***\tLoss: 278.4035,\tAccuracy: 66.78% (6678/10000)\n",
      "\n",
      "Training Epoch: 3.76% (188/5000)\tBatch: 100.00% (20/20)\tLoss: 930.569824\n",
      "***Validation Results***\tLoss: 278.6365,\tAccuracy: 66.87% (6687/10000)\n",
      "\n",
      "Training Epoch: 3.78% (189/5000)\tBatch: 100.00% (20/20)\tLoss: 1019.384338\n",
      "***Validation Results***\tLoss: 278.0906,\tAccuracy: 67.00% (6700/10000)\n",
      "\n",
      "Training Epoch: 3.80% (190/5000)\tBatch: 100.00% (20/20)\tLoss: 1033.842041\n",
      "***Validation Results***\tLoss: 276.7703,\tAccuracy: 67.38% (6738/10000)\n",
      "\n",
      "Training Epoch: 3.82% (191/5000)\tBatch: 100.00% (20/20)\tLoss: 1075.831543\n",
      "***Validation Results***\tLoss: 274.7345,\tAccuracy: 67.67% (6767/10000)\n",
      "\n",
      "Training Epoch: 3.84% (192/5000)\tBatch: 100.00% (20/20)\tLoss: 1027.620483\n",
      "***Validation Results***\tLoss: 271.9821,\tAccuracy: 67.92% (6792/10000)\n",
      "\n",
      "Training Epoch: 3.86% (193/5000)\tBatch: 100.00% (20/20)\tLoss: 1207.531738\n",
      "***Validation Results***\tLoss: 268.6007,\tAccuracy: 67.98% (6798/10000)\n",
      "\n",
      "Training Epoch: 3.88% (194/5000)\tBatch: 100.00% (20/20)\tLoss: 1097.487061\n",
      "***Validation Results***\tLoss: 264.5911,\tAccuracy: 68.07% (6807/10000)\n",
      "\n",
      "Training Epoch: 3.90% (195/5000)\tBatch: 100.00% (20/20)\tLoss: 1173.450439\n",
      "***Validation Results***\tLoss: 260.0927,\tAccuracy: 68.23% (6823/10000)\n",
      "\n",
      "Training Epoch: 3.92% (196/5000)\tBatch: 100.00% (20/20)\tLoss: 1122.690308\n",
      "***Validation Results***\tLoss: 255.3585,\tAccuracy: 68.89% (6889/10000)\n",
      "\n",
      "Training Epoch: 3.94% (197/5000)\tBatch: 100.00% (20/20)\tLoss: 1147.734863\n",
      "***Validation Results***\tLoss: 250.5679,\tAccuracy: 69.10% (6910/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 3.96% (198/5000)\tBatch: 100.00% (20/20)\tLoss: 1306.301636\n",
      "***Validation Results***\tLoss: 245.8844,\tAccuracy: 69.19% (6919/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 3.98% (199/5000)\tBatch: 100.00% (20/20)\tLoss: 1171.962646\n",
      "***Validation Results***\tLoss: 241.5494,\tAccuracy: 69.25% (6925/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 4.00% (200/5000)\tBatch: 100.00% (20/20)\tLoss: 1242.819092\n",
      "***Validation Results***\tLoss: 237.9522,\tAccuracy: 68.60% (6860/10000)\n",
      "\n",
      "Training Epoch: 4.02% (201/5000)\tBatch: 100.00% (20/20)\tLoss: 1172.482544\n",
      "***Validation Results***\tLoss: 235.5082,\tAccuracy: 68.28% (6828/10000)\n",
      "\n",
      "Training Epoch: 4.04% (202/5000)\tBatch: 100.00% (20/20)\tLoss: 1294.184326\n",
      "***Validation Results***\tLoss: 234.7241,\tAccuracy: 67.33% (6733/10000)\n",
      "\n",
      "Training Epoch: 4.06% (203/5000)\tBatch: 100.00% (20/20)\tLoss: 1095.119873\n",
      "***Validation Results***\tLoss: 235.2037,\tAccuracy: 65.10% (6510/10000)\n",
      "\n",
      "Training Epoch: 4.08% (204/5000)\tBatch: 100.00% (20/20)\tLoss: 1198.646851\n",
      "***Validation Results***\tLoss: 235.7528,\tAccuracy: 64.39% (6439/10000)\n",
      "\n",
      "Training Epoch: 4.10% (205/5000)\tBatch: 100.00% (20/20)\tLoss: 1300.766846\n",
      "***Validation Results***\tLoss: 235.5039,\tAccuracy: 64.45% (6445/10000)\n",
      "\n",
      "Training Epoch: 4.12% (206/5000)\tBatch: 100.00% (20/20)\tLoss: 1207.042358\n",
      "***Validation Results***\tLoss: 234.5211,\tAccuracy: 65.52% (6552/10000)\n",
      "\n",
      "Training Epoch: 4.14% (207/5000)\tBatch: 100.00% (20/20)\tLoss: 1172.929077\n",
      "***Validation Results***\tLoss: 234.1323,\tAccuracy: 67.90% (6790/10000)\n",
      "\n",
      "Training Epoch: 4.16% (208/5000)\tBatch: 100.00% (20/20)\tLoss: 1210.580688\n",
      "***Validation Results***\tLoss: 235.8974,\tAccuracy: 68.60% (6860/10000)\n",
      "\n",
      "Training Epoch: 4.18% (209/5000)\tBatch: 100.00% (20/20)\tLoss: 1058.761108\n",
      "***Validation Results***\tLoss: 239.8606,\tAccuracy: 69.07% (6907/10000)\n",
      "\n",
      "Training Epoch: 4.20% (210/5000)\tBatch: 100.00% (20/20)\tLoss: 1093.901733\n",
      "***Validation Results***\tLoss: 245.3178,\tAccuracy: 69.30% (6930/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 4.22% (211/5000)\tBatch: 100.00% (20/20)\tLoss: 1078.472900\n",
      "***Validation Results***\tLoss: 251.6590,\tAccuracy: 69.10% (6910/10000)\n",
      "\n",
      "Training Epoch: 4.24% (212/5000)\tBatch: 100.00% (20/20)\tLoss: 1040.938110\n",
      "***Validation Results***\tLoss: 258.4056,\tAccuracy: 69.07% (6907/10000)\n",
      "\n",
      "Training Epoch: 4.26% (213/5000)\tBatch: 100.00% (20/20)\tLoss: 996.361755\n",
      "***Validation Results***\tLoss: 265.2784,\tAccuracy: 68.29% (6829/10000)\n",
      "\n",
      "Training Epoch: 4.28% (214/5000)\tBatch: 100.00% (20/20)\tLoss: 1007.008240\n",
      "***Validation Results***\tLoss: 271.8182,\tAccuracy: 68.51% (6851/10000)\n",
      "\n",
      "Training Epoch: 4.30% (215/5000)\tBatch: 100.00% (20/20)\tLoss: 905.003235\n",
      "***Validation Results***\tLoss: 277.6547,\tAccuracy: 68.36% (6836/10000)\n",
      "\n",
      "Training Epoch: 4.32% (216/5000)\tBatch: 100.00% (20/20)\tLoss: 852.657837\n",
      "***Validation Results***\tLoss: 282.6102,\tAccuracy: 68.07% (6807/10000)\n",
      "\n",
      "Training Epoch: 4.34% (217/5000)\tBatch: 100.00% (20/20)\tLoss: 857.104248\n",
      "***Validation Results***\tLoss: 286.4790,\tAccuracy: 67.89% (6789/10000)\n",
      "\n",
      "Training Epoch: 4.36% (218/5000)\tBatch: 100.00% (20/20)\tLoss: 781.587402\n",
      "***Validation Results***\tLoss: 289.2711,\tAccuracy: 67.52% (6752/10000)\n",
      "\n",
      "Training Epoch: 4.38% (219/5000)\tBatch: 100.00% (20/20)\tLoss: 714.970215\n",
      "***Validation Results***\tLoss: 290.9385,\tAccuracy: 67.39% (6739/10000)\n",
      "\n",
      "Training Epoch: 4.40% (220/5000)\tBatch: 100.00% (20/20)\tLoss: 647.465332\n",
      "***Validation Results***\tLoss: 291.4140,\tAccuracy: 67.16% (6716/10000)\n",
      "\n",
      "Training Epoch: 4.42% (221/5000)\tBatch: 100.00% (20/20)\tLoss: 675.374695\n",
      "***Validation Results***\tLoss: 290.7088,\tAccuracy: 67.13% (6713/10000)\n",
      "\n",
      "Training Epoch: 4.44% (222/5000)\tBatch: 100.00% (20/20)\tLoss: 502.051392\n",
      "***Validation Results***\tLoss: 288.7930,\tAccuracy: 67.14% (6714/10000)\n",
      "\n",
      "Training Epoch: 4.46% (223/5000)\tBatch: 100.00% (20/20)\tLoss: 476.450073\n",
      "***Validation Results***\tLoss: 285.7571,\tAccuracy: 67.20% (6720/10000)\n",
      "\n",
      "Training Epoch: 4.48% (224/5000)\tBatch: 100.00% (20/20)\tLoss: 417.101654\n",
      "***Validation Results***\tLoss: 281.6880,\tAccuracy: 67.45% (6745/10000)\n",
      "\n",
      "Training Epoch: 4.50% (225/5000)\tBatch: 100.00% (20/20)\tLoss: 279.241028\n",
      "***Validation Results***\tLoss: 276.6318,\tAccuracy: 67.69% (6769/10000)\n",
      "\n",
      "Training Epoch: 4.52% (226/5000)\tBatch: 100.00% (20/20)\tLoss: 220.263702\n",
      "***Validation Results***\tLoss: 270.4767,\tAccuracy: 67.99% (6799/10000)\n",
      "\n",
      "Training Epoch: 4.54% (227/5000)\tBatch: 100.00% (20/20)\tLoss: 227.610916\n",
      "***Validation Results***\tLoss: 262.4543,\tAccuracy: 68.33% (6833/10000)\n",
      "\n",
      "Training Epoch: 4.56% (228/5000)\tBatch: 100.00% (20/20)\tLoss: 254.320877\n",
      "***Validation Results***\tLoss: 251.0751,\tAccuracy: 68.52% (6852/10000)\n",
      "\n",
      "Training Epoch: 4.58% (229/5000)\tBatch: 100.00% (20/20)\tLoss: 343.876190\n",
      "***Validation Results***\tLoss: 237.6015,\tAccuracy: 68.47% (6847/10000)\n",
      "\n",
      "Training Epoch: 4.60% (230/5000)\tBatch: 100.00% (20/20)\tLoss: 448.353607\n",
      "***Validation Results***\tLoss: 225.1885,\tAccuracy: 69.10% (6910/10000)\n",
      "\n",
      "Training Epoch: 4.62% (231/5000)\tBatch: 100.00% (20/20)\tLoss: 583.553467\n",
      "***Validation Results***\tLoss: 214.7823,\tAccuracy: 69.31% (6931/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 4.64% (232/5000)\tBatch: 100.00% (20/20)\tLoss: 701.304443\n",
      "***Validation Results***\tLoss: 206.1258,\tAccuracy: 69.38% (6938/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 4.66% (233/5000)\tBatch: 100.00% (20/20)\tLoss: 803.802246\n",
      "***Validation Results***\tLoss: 199.1615,\tAccuracy: 68.95% (6895/10000)\n",
      "\n",
      "Training Epoch: 4.68% (234/5000)\tBatch: 100.00% (20/20)\tLoss: 857.697876\n",
      "***Validation Results***\tLoss: 193.7928,\tAccuracy: 68.74% (6874/10000)\n",
      "\n",
      "Training Epoch: 4.70% (235/5000)\tBatch: 100.00% (20/20)\tLoss: 973.161438\n",
      "***Validation Results***\tLoss: 189.7071,\tAccuracy: 68.37% (6837/10000)\n",
      "\n",
      "Training Epoch: 4.72% (236/5000)\tBatch: 100.00% (20/20)\tLoss: 960.899902\n",
      "***Validation Results***\tLoss: 186.7682,\tAccuracy: 68.13% (6813/10000)\n",
      "\n",
      "Training Epoch: 4.74% (237/5000)\tBatch: 100.00% (20/20)\tLoss: 1031.092285\n",
      "***Validation Results***\tLoss: 184.7899,\tAccuracy: 67.85% (6785/10000)\n",
      "\n",
      "Training Epoch: 4.76% (238/5000)\tBatch: 100.00% (20/20)\tLoss: 1120.529663\n",
      "***Validation Results***\tLoss: 183.4603,\tAccuracy: 67.18% (6718/10000)\n",
      "\n",
      "Training Epoch: 4.78% (239/5000)\tBatch: 100.00% (20/20)\tLoss: 1225.709351\n",
      "***Validation Results***\tLoss: 182.4535,\tAccuracy: 66.62% (6662/10000)\n",
      "\n",
      "Training Epoch: 4.80% (240/5000)\tBatch: 100.00% (20/20)\tLoss: 1241.875366\n",
      "***Validation Results***\tLoss: 181.5103,\tAccuracy: 66.43% (6643/10000)\n",
      "\n",
      "Training Epoch: 4.82% (241/5000)\tBatch: 100.00% (20/20)\tLoss: 1216.172241\n",
      "***Validation Results***\tLoss: 180.4911,\tAccuracy: 66.53% (6653/10000)\n",
      "\n",
      "Training Epoch: 4.84% (242/5000)\tBatch: 100.00% (20/20)\tLoss: 1201.276123\n",
      "***Validation Results***\tLoss: 179.4134,\tAccuracy: 66.99% (6699/10000)\n",
      "\n",
      "Training Epoch: 4.86% (243/5000)\tBatch: 100.00% (20/20)\tLoss: 1224.287354\n",
      "***Validation Results***\tLoss: 178.5063,\tAccuracy: 67.35% (6735/10000)\n",
      "\n",
      "Training Epoch: 4.88% (244/5000)\tBatch: 100.00% (20/20)\tLoss: 1167.267578\n",
      "***Validation Results***\tLoss: 178.0700,\tAccuracy: 67.80% (6780/10000)\n",
      "\n",
      "Training Epoch: 4.90% (245/5000)\tBatch: 100.00% (20/20)\tLoss: 1117.691406\n",
      "***Validation Results***\tLoss: 178.4820,\tAccuracy: 68.31% (6831/10000)\n",
      "\n",
      "Training Epoch: 4.92% (246/5000)\tBatch: 100.00% (20/20)\tLoss: 1032.021973\n",
      "***Validation Results***\tLoss: 179.9891,\tAccuracy: 68.40% (6840/10000)\n",
      "\n",
      "Training Epoch: 4.94% (247/5000)\tBatch: 100.00% (20/20)\tLoss: 1101.433960\n",
      "***Validation Results***\tLoss: 182.7480,\tAccuracy: 68.90% (6890/10000)\n",
      "\n",
      "Training Epoch: 4.96% (248/5000)\tBatch: 100.00% (20/20)\tLoss: 973.541077\n",
      "***Validation Results***\tLoss: 186.8028,\tAccuracy: 69.19% (6919/10000)\n",
      "\n",
      "Training Epoch: 4.98% (249/5000)\tBatch: 100.00% (20/20)\tLoss: 834.048584\n",
      "***Validation Results***\tLoss: 192.2900,\tAccuracy: 69.50% (6950/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 5.00% (250/5000)\tBatch: 100.00% (20/20)\tLoss: 730.815186\n",
      "***Validation Results***\tLoss: 199.1001,\tAccuracy: 69.60% (6960/10000)\n",
      "\n",
      "model saved to models/rev_best.pth\n",
      "Training Epoch: 5.02% (251/5000)\tBatch: 100.00% (20/20)\tLoss: 678.384827\n",
      "***Validation Results***\tLoss: 207.0622,\tAccuracy: 69.28% (6928/10000)\n",
      "\n",
      "Training Epoch: 5.04% (252/5000)\tBatch: 100.00% (20/20)\tLoss: 553.207581\n",
      "***Validation Results***\tLoss: 216.1761,\tAccuracy: 68.97% (6897/10000)\n",
      "\n",
      "Training Epoch: 5.06% (253/5000)\tBatch: 100.00% (20/20)\tLoss: 478.506805\n",
      "***Validation Results***\tLoss: 226.1521,\tAccuracy: 68.84% (6884/10000)\n",
      "\n",
      "Training Epoch: 5.08% (254/5000)\tBatch: 100.00% (20/20)\tLoss: 248.961105\n",
      "***Validation Results***\tLoss: 236.6798,\tAccuracy: 69.14% (6914/10000)\n",
      "\n",
      "Training Epoch: 5.10% (255/5000)\tBatch: 100.00% (20/20)\tLoss: 228.089188\n",
      "***Validation Results***\tLoss: 246.8874,\tAccuracy: 68.68% (6868/10000)\n",
      "\n",
      "Training Epoch: 5.12% (256/5000)\tBatch: 100.00% (20/20)\tLoss: 247.209244\n",
      "***Validation Results***\tLoss: 253.6815,\tAccuracy: 68.22% (6822/10000)\n",
      "\n",
      "Training Epoch: 5.14% (257/5000)\tBatch: 100.00% (20/20)\tLoss: 222.531189\n",
      "***Validation Results***\tLoss: 255.8451,\tAccuracy: 68.18% (6818/10000)\n",
      "\n",
      "Training Epoch: 5.16% (258/5000)\tBatch: 100.00% (20/20)\tLoss: 309.688873\n",
      "***Validation Results***\tLoss: 255.0034,\tAccuracy: 68.23% (6823/10000)\n",
      "\n",
      "Training Epoch: 5.18% (259/5000)\tBatch: 100.00% (20/20)\tLoss: 390.816864\n",
      "***Validation Results***\tLoss: 252.8820,\tAccuracy: 68.61% (6861/10000)\n",
      "\n",
      "Training Epoch: 5.20% (260/5000)\tBatch: 100.00% (20/20)\tLoss: 440.671356\n",
      "***Validation Results***\tLoss: 250.0777,\tAccuracy: 68.98% (6898/10000)\n",
      "\n",
      "Training Epoch: 5.22% (261/5000)\tBatch: 100.00% (20/20)\tLoss: 497.014587\n",
      "***Validation Results***\tLoss: 246.7697,\tAccuracy: 69.19% (6919/10000)\n",
      "\n",
      "Training Epoch: 5.24% (262/5000)\tBatch: 100.00% (20/20)\tLoss: 597.993774\n",
      "***Validation Results***\tLoss: 243.0338,\tAccuracy: 69.21% (6921/10000)\n",
      "\n",
      "Training Epoch: 5.26% (263/5000)\tBatch: 100.00% (20/20)\tLoss: 629.680176\n",
      "***Validation Results***\tLoss: 238.9537,\tAccuracy: 69.07% (6907/10000)\n",
      "\n",
      "Training Epoch: 5.28% (264/5000)\tBatch: 100.00% (20/20)\tLoss: 659.773560\n",
      "***Validation Results***\tLoss: 234.6277,\tAccuracy: 68.93% (6893/10000)\n",
      "\n",
      "Training Epoch: 5.30% (265/5000)\tBatch: 100.00% (20/20)\tLoss: 733.032654\n",
      "***Validation Results***\tLoss: 230.0420,\tAccuracy: 68.95% (6895/10000)\n",
      "\n",
      "Training Epoch: 5.32% (266/5000)\tBatch: 100.00% (20/20)\tLoss: 808.994629\n",
      "***Validation Results***\tLoss: 225.2292,\tAccuracy: 69.19% (6919/10000)\n",
      "\n",
      "Training Epoch: 5.34% (267/5000)\tBatch: 100.00% (20/20)\tLoss: 914.392395\n",
      "***Validation Results***\tLoss: 220.2249,\tAccuracy: 69.00% (6900/10000)\n",
      "\n",
      "Training Epoch: 5.36% (268/5000)\tBatch: 100.00% (20/20)\tLoss: 851.505249\n",
      "***Validation Results***\tLoss: 215.1458,\tAccuracy: 69.34% (6934/10000)\n",
      "\n",
      "Training Epoch: 5.38% (269/5000)\tBatch: 100.00% (20/20)\tLoss: 952.808838\n",
      "***Validation Results***\tLoss: 210.1074,\tAccuracy: 69.48% (6948/10000)\n",
      "\n",
      "Training Epoch: 5.40% (270/5000)\tBatch: 100.00% (20/20)\tLoss: 963.628540\n",
      "***Validation Results***\tLoss: 205.1372,\tAccuracy: 69.49% (6949/10000)\n",
      "\n",
      "Training Epoch: 5.42% (271/5000)\tBatch: 100.00% (20/20)\tLoss: 981.316467\n",
      "***Validation Results***\tLoss: 200.2940,\tAccuracy: 69.40% (6940/10000)\n",
      "\n",
      "Training Epoch: 5.44% (272/5000)\tBatch: 100.00% (20/20)\tLoss: 950.372925\n",
      "***Validation Results***\tLoss: 195.6696,\tAccuracy: 69.30% (6930/10000)\n",
      "\n",
      "Training Epoch: 5.46% (273/5000)\tBatch: 100.00% (20/20)\tLoss: 978.542175\n",
      "***Validation Results***\tLoss: 191.3684,\tAccuracy: 69.07% (6907/10000)\n",
      "\n",
      "Training Epoch: 5.48% (274/5000)\tBatch: 100.00% (20/20)\tLoss: 1056.640259\n",
      "***Validation Results***\tLoss: 187.5336,\tAccuracy: 69.02% (6902/10000)\n",
      "\n",
      "Training Epoch: 5.50% (275/5000)\tBatch: 100.00% (20/20)\tLoss: 1063.087646\n",
      "***Validation Results***\tLoss: 184.0981,\tAccuracy: 68.79% (6879/10000)\n",
      "\n",
      "Training Epoch: 5.52% (276/5000)\tBatch: 100.00% (20/20)\tLoss: 1079.659912\n",
      "***Validation Results***\tLoss: 181.0860,\tAccuracy: 68.58% (6858/10000)\n",
      "\n",
      "Training Epoch: 5.54% (277/5000)\tBatch: 100.00% (20/20)\tLoss: 1141.190063\n",
      "***Validation Results***\tLoss: 178.4890,\tAccuracy: 68.26% (6826/10000)\n",
      "\n",
      "Training Epoch: 5.56% (278/5000)\tBatch: 100.00% (20/20)\tLoss: 1218.076660\n",
      "***Validation Results***\tLoss: 176.2965,\tAccuracy: 67.77% (6777/10000)\n",
      "\n",
      "Training Epoch: 5.58% (279/5000)\tBatch: 100.00% (20/20)\tLoss: 1154.025635\n",
      "***Validation Results***\tLoss: 174.4523,\tAccuracy: 67.57% (6757/10000)\n",
      "\n",
      "Training Epoch: 5.60% (280/5000)\tBatch: 100.00% (20/20)\tLoss: 1127.555420\n",
      "***Validation Results***\tLoss: 172.8961,\tAccuracy: 67.49% (6749/10000)\n",
      "\n",
      "Training Epoch: 5.62% (281/5000)\tBatch: 100.00% (20/20)\tLoss: 1169.713501\n",
      "***Validation Results***\tLoss: 171.6180,\tAccuracy: 67.47% (6747/10000)\n",
      "\n",
      "Training Epoch: 5.64% (282/5000)\tBatch: 100.00% (20/20)\tLoss: 1196.660278\n",
      "***Validation Results***\tLoss: 170.6464,\tAccuracy: 67.65% (6765/10000)\n",
      "\n",
      "Training Epoch: 5.66% (283/5000)\tBatch: 100.00% (20/20)\tLoss: 1216.754517\n",
      "***Validation Results***\tLoss: 170.0809,\tAccuracy: 68.03% (6803/10000)\n",
      "\n",
      "Training Epoch: 5.68% (284/5000)\tBatch: 100.00% (20/20)\tLoss: 1175.655884\n",
      "***Validation Results***\tLoss: 170.0414,\tAccuracy: 68.62% (6862/10000)\n",
      "\n",
      "Training Epoch: 5.70% (285/5000)\tBatch: 100.00% (20/20)\tLoss: 1148.263916\n",
      "***Validation Results***\tLoss: 170.6096,\tAccuracy: 68.73% (6873/10000)\n",
      "\n",
      "Training Epoch: 5.72% (286/5000)\tBatch: 100.00% (20/20)\tLoss: 1109.797363\n",
      "***Validation Results***\tLoss: 171.8094,\tAccuracy: 68.87% (6887/10000)\n",
      "\n",
      "Training Epoch: 5.74% (287/5000)\tBatch: 100.00% (20/20)\tLoss: 1122.905640\n",
      "***Validation Results***\tLoss: 173.6242,\tAccuracy: 68.97% (6897/10000)\n",
      "\n",
      "Training Epoch: 5.76% (288/5000)\tBatch: 100.00% (20/20)\tLoss: 1080.984497\n",
      "***Validation Results***\tLoss: 176.0565,\tAccuracy: 69.36% (6936/10000)\n",
      "\n",
      "Training Epoch: 5.78% (289/5000)\tBatch: 100.00% (20/20)\tLoss: 1094.907837\n",
      "***Validation Results***\tLoss: 178.9175,\tAccuracy: 69.15% (6915/10000)\n",
      "\n",
      "Training Epoch: 5.80% (290/5000)\tBatch: 100.00% (20/20)\tLoss: 1087.985107\n",
      "***Validation Results***\tLoss: 182.0662,\tAccuracy: 69.30% (6930/10000)\n",
      "\n",
      "Training Epoch: 5.82% (291/5000)\tBatch: 100.00% (20/20)\tLoss: 1045.171143\n",
      "***Validation Results***\tLoss: 185.3551,\tAccuracy: 69.01% (6901/10000)\n",
      "\n",
      "Training Epoch: 5.84% (292/5000)\tBatch: 100.00% (20/20)\tLoss: 936.518738\n",
      "***Validation Results***\tLoss: 188.6523,\tAccuracy: 68.78% (6878/10000)\n",
      "\n",
      "Training Epoch: 5.86% (293/5000)\tBatch: 100.00% (20/20)\tLoss: 878.851746\n",
      "***Validation Results***\tLoss: 191.7186,\tAccuracy: 68.76% (6876/10000)\n",
      "\n",
      "Training Epoch: 5.88% (294/5000)\tBatch: 100.00% (20/20)\tLoss: 900.798279\n",
      "***Validation Results***\tLoss: 194.4453,\tAccuracy: 68.76% (6876/10000)\n",
      "\n",
      "Training Epoch: 5.90% (295/5000)\tBatch: 100.00% (20/20)\tLoss: 804.835327\n",
      "***Validation Results***\tLoss: 196.7550,\tAccuracy: 68.73% (6873/10000)\n",
      "\n",
      "Training Epoch: 5.92% (296/5000)\tBatch: 100.00% (20/20)\tLoss: 785.372253\n",
      "***Validation Results***\tLoss: 198.4890,\tAccuracy: 68.96% (6896/10000)\n",
      "\n",
      "Training Epoch: 5.94% (297/5000)\tBatch: 100.00% (20/20)\tLoss: 785.556946\n",
      "***Validation Results***\tLoss: 199.5666,\tAccuracy: 68.95% (6895/10000)\n",
      "\n",
      "Training Epoch: 5.96% (298/5000)\tBatch: 100.00% (20/20)\tLoss: 697.733826\n",
      "***Validation Results***\tLoss: 199.9204,\tAccuracy: 68.94% (6894/10000)\n",
      "\n",
      "Training Epoch: 5.98% (299/5000)\tBatch: 100.00% (20/20)\tLoss: 623.186523\n",
      "***Validation Results***\tLoss: 199.5150,\tAccuracy: 68.92% (6892/10000)\n",
      "\n",
      "Training Epoch: 6.00% (300/5000)\tBatch: 100.00% (20/20)\tLoss: 545.967834\n",
      "***Validation Results***\tLoss: 198.3348,\tAccuracy: 68.88% (6888/10000)\n",
      "\n",
      "Training Epoch: 6.02% (301/5000)\tBatch: 100.00% (20/20)\tLoss: 463.908539\n",
      "***Validation Results***\tLoss: 196.3688,\tAccuracy: 68.91% (6891/10000)\n",
      "\n",
      "Training Epoch: 6.04% (302/5000)\tBatch: 100.00% (20/20)\tLoss: 468.789948\n",
      "***Validation Results***\tLoss: 193.5956,\tAccuracy: 68.94% (6894/10000)\n",
      "\n",
      "Training Epoch: 6.06% (303/5000)\tBatch: 100.00% (20/20)\tLoss: 324.953430\n",
      "***Validation Results***\tLoss: 190.0846,\tAccuracy: 68.97% (6897/10000)\n",
      "\n",
      "Training Epoch: 6.08% (304/5000)\tBatch: 100.00% (20/20)\tLoss: 298.163971\n",
      "***Validation Results***\tLoss: 185.9263,\tAccuracy: 68.97% (6897/10000)\n",
      "\n",
      "Training Epoch: 6.10% (305/5000)\tBatch: 100.00% (20/20)\tLoss: 209.354691\n",
      "***Validation Results***\tLoss: 181.0878,\tAccuracy: 68.92% (6892/10000)\n",
      "\n",
      "Training Epoch: 6.12% (306/5000)\tBatch: 100.00% (20/20)\tLoss: 182.460403\n",
      "***Validation Results***\tLoss: 175.2272,\tAccuracy: 68.99% (6899/10000)\n",
      "\n",
      "Training Epoch: 6.14% (307/5000)\tBatch: 100.00% (20/20)\tLoss: 151.003601\n",
      "***Validation Results***\tLoss: 166.9548,\tAccuracy: 68.95% (6895/10000)\n",
      "\n",
      "Training Epoch: 6.16% (308/5000)\tBatch: 100.00% (20/20)\tLoss: 178.181091\n",
      "***Validation Results***\tLoss: 155.2836,\tAccuracy: 68.87% (6887/10000)\n",
      "\n",
      "Training Epoch: 6.18% (309/5000)\tBatch: 100.00% (20/20)\tLoss: 317.944946\n",
      "***Validation Results***\tLoss: 141.6286,\tAccuracy: 68.66% (6866/10000)\n",
      "\n",
      "Training Epoch: 6.20% (310/5000)\tBatch: 100.00% (20/20)\tLoss: 397.054108\n",
      "***Validation Results***\tLoss: 128.5902,\tAccuracy: 68.76% (6876/10000)\n",
      "\n",
      "Training Epoch: 6.22% (311/5000)\tBatch: 100.00% (20/20)\tLoss: 506.696899\n",
      "***Validation Results***\tLoss: 117.0853,\tAccuracy: 69.41% (6941/10000)\n",
      "\n",
      "Training Epoch: 6.24% (312/5000)\tBatch: 100.00% (20/20)\tLoss: 626.131653\n",
      "***Validation Results***\tLoss: 107.1911,\tAccuracy: 69.29% (6929/10000)\n",
      "\n",
      "Training Epoch: 6.26% (313/5000)\tBatch: 100.00% (20/20)\tLoss: 704.946655\n",
      "***Validation Results***\tLoss: 98.7700,\tAccuracy: 69.16% (6916/10000)\n",
      "\n",
      "Training Epoch: 6.28% (314/5000)\tBatch: 100.00% (20/20)\tLoss: 813.553162\n",
      "***Validation Results***\tLoss: 91.7403,\tAccuracy: 69.02% (6902/10000)\n",
      "\n",
      "Training Epoch: 6.30% (315/5000)\tBatch: 100.00% (20/20)\tLoss: 868.735413\n",
      "***Validation Results***\tLoss: 85.8491,\tAccuracy: 68.43% (6843/10000)\n",
      "\n",
      "Training Epoch: 6.32% (316/5000)\tBatch: 100.00% (20/20)\tLoss: 959.557983\n",
      "***Validation Results***\tLoss: 80.8867,\tAccuracy: 67.98% (6798/10000)\n",
      "\n",
      "Training Epoch: 6.34% (317/5000)\tBatch: 100.00% (20/20)\tLoss: 1001.449341\n",
      "***Validation Results***\tLoss: 76.7140,\tAccuracy: 67.63% (6763/10000)\n",
      "\n",
      "Training Epoch: 6.36% (318/5000)\tBatch: 100.00% (20/20)\tLoss: 1001.919617\n",
      "***Validation Results***\tLoss: 73.2672,\tAccuracy: 66.92% (6692/10000)\n",
      "\n",
      "Training Epoch: 6.38% (319/5000)\tBatch: 100.00% (20/20)\tLoss: 1039.126221\n",
      "***Validation Results***\tLoss: 70.4227,\tAccuracy: 66.07% (6607/10000)\n",
      "\n",
      "Training Epoch: 6.40% (320/5000)\tBatch: 100.00% (20/20)\tLoss: 1044.759399\n",
      "***Validation Results***\tLoss: 68.0685,\tAccuracy: 65.72% (6572/10000)\n",
      "\n",
      "Training Epoch: 6.42% (321/5000)\tBatch: 100.00% (20/20)\tLoss: 1084.746338\n",
      "***Validation Results***\tLoss: 66.1250,\tAccuracy: 65.59% (6559/10000)\n",
      "\n",
      "Training Epoch: 6.44% (322/5000)\tBatch: 100.00% (20/20)\tLoss: 1061.139771\n",
      "***Validation Results***\tLoss: 64.5241,\tAccuracy: 65.40% (6540/10000)\n",
      "\n",
      "Training Epoch: 6.46% (323/5000)\tBatch: 100.00% (20/20)\tLoss: 1041.260498\n",
      "***Validation Results***\tLoss: 63.2338,\tAccuracy: 65.29% (6529/10000)\n",
      "\n",
      "Training Epoch: 6.48% (324/5000)\tBatch: 100.00% (20/20)\tLoss: 1028.556274\n",
      "***Validation Results***\tLoss: 62.2453,\tAccuracy: 65.35% (6535/10000)\n",
      "\n",
      "Training Epoch: 6.50% (325/5000)\tBatch: 100.00% (20/20)\tLoss: 976.265930\n",
      "***Validation Results***\tLoss: 61.5957,\tAccuracy: 65.33% (6533/10000)\n",
      "\n",
      "Training Epoch: 6.52% (326/5000)\tBatch: 100.00% (20/20)\tLoss: 943.116211\n",
      "***Validation Results***\tLoss: 61.3626,\tAccuracy: 65.45% (6545/10000)\n",
      "\n",
      "Training Epoch: 6.54% (327/5000)\tBatch: 100.00% (20/20)\tLoss: 875.234802\n",
      "***Validation Results***\tLoss: 61.6268,\tAccuracy: 65.83% (6583/10000)\n",
      "\n",
      "Training Epoch: 6.56% (328/5000)\tBatch: 100.00% (20/20)\tLoss: 795.936523\n",
      "***Validation Results***\tLoss: 62.5014,\tAccuracy: 66.24% (6624/10000)\n",
      "\n",
      "Training Epoch: 6.58% (329/5000)\tBatch: 100.00% (20/20)\tLoss: 711.718445\n",
      "***Validation Results***\tLoss: 64.0904,\tAccuracy: 66.74% (6674/10000)\n",
      "\n",
      "Training Epoch: 6.60% (330/5000)\tBatch: 100.00% (20/20)\tLoss: 632.470337\n",
      "***Validation Results***\tLoss: 66.3972,\tAccuracy: 67.07% (6707/10000)\n",
      "\n",
      "Training Epoch: 6.62% (331/5000)\tBatch: 100.00% (20/20)\tLoss: 510.689880\n",
      "***Validation Results***\tLoss: 69.4484,\tAccuracy: 67.41% (6741/10000)\n",
      "\n",
      "Training Epoch: 6.64% (332/5000)\tBatch: 100.00% (20/20)\tLoss: 357.575836\n",
      "***Validation Results***\tLoss: 73.2699,\tAccuracy: 67.62% (6762/10000)\n",
      "\n",
      "Training Epoch: 6.66% (333/5000)\tBatch: 100.00% (20/20)\tLoss: 240.687286\n",
      "***Validation Results***\tLoss: 77.8516,\tAccuracy: 67.78% (6778/10000)\n",
      "\n",
      "Training Epoch: 6.68% (334/5000)\tBatch: 100.00% (20/20)\tLoss: 123.771767\n",
      "***Validation Results***\tLoss: 83.1058,\tAccuracy: 68.22% (6822/10000)\n",
      "\n",
      "Training Epoch: 6.70% (335/5000)\tBatch: 100.00% (20/20)\tLoss: 82.877602\n",
      "***Validation Results***\tLoss: 87.8863,\tAccuracy: 68.15% (6815/10000)\n",
      "\n",
      "Training Epoch: 6.72% (336/5000)\tBatch: 100.00% (20/20)\tLoss: 117.500511\n",
      "***Validation Results***\tLoss: 90.4504,\tAccuracy: 68.27% (6827/10000)\n",
      "\n",
      "Training Epoch: 6.74% (337/5000)\tBatch: 100.00% (20/20)\tLoss: 186.727951\n",
      "***Validation Results***\tLoss: 91.3634,\tAccuracy: 68.22% (6822/10000)\n",
      "\n",
      "Training Epoch: 6.76% (338/5000)\tBatch: 100.00% (20/20)\tLoss: 250.034912\n",
      "***Validation Results***\tLoss: 91.7944,\tAccuracy: 68.22% (6822/10000)\n",
      "\n",
      "Training Epoch: 6.78% (339/5000)\tBatch: 100.00% (20/20)\tLoss: 329.034393\n",
      "***Validation Results***\tLoss: 92.1522,\tAccuracy: 68.23% (6823/10000)\n",
      "\n",
      "Training Epoch: 6.80% (340/5000)\tBatch: 100.00% (20/20)\tLoss: 347.803925\n",
      "***Validation Results***\tLoss: 92.5137,\tAccuracy: 68.18% (6818/10000)\n",
      "\n",
      "Training Epoch: 6.82% (341/5000)\tBatch: 100.00% (20/20)\tLoss: 448.454773\n",
      "***Validation Results***\tLoss: 92.9263,\tAccuracy: 68.17% (6817/10000)\n",
      "\n",
      "Training Epoch: 6.84% (342/5000)\tBatch: 100.00% (20/20)\tLoss: 496.277008\n",
      "***Validation Results***\tLoss: 93.3802,\tAccuracy: 67.98% (6798/10000)\n",
      "\n",
      "Training Epoch: 6.86% (343/5000)\tBatch: 100.00% (20/20)\tLoss: 597.566895\n",
      "***Validation Results***\tLoss: 93.8547,\tAccuracy: 67.97% (6797/10000)\n",
      "\n",
      "Training Epoch: 6.88% (344/5000)\tBatch: 100.00% (20/20)\tLoss: 622.341431\n",
      "***Validation Results***\tLoss: 94.4478,\tAccuracy: 68.02% (6802/10000)\n",
      "\n",
      "Training Epoch: 6.90% (345/5000)\tBatch: 100.00% (20/20)\tLoss: 659.467102\n",
      "***Validation Results***\tLoss: 95.2406,\tAccuracy: 67.98% (6798/10000)\n",
      "\n",
      "Training Epoch: 6.92% (346/5000)\tBatch: 100.00% (20/20)\tLoss: 771.261658\n",
      "***Validation Results***\tLoss: 96.2766,\tAccuracy: 68.03% (6803/10000)\n",
      "\n",
      "Training Epoch: 6.94% (347/5000)\tBatch: 100.00% (20/20)\tLoss: 833.740784\n",
      "***Validation Results***\tLoss: 97.5569,\tAccuracy: 68.09% (6809/10000)\n",
      "\n",
      "Training Epoch: 6.96% (348/5000)\tBatch: 100.00% (20/20)\tLoss: 912.963806\n",
      "***Validation Results***\tLoss: 99.0788,\tAccuracy: 68.02% (6802/10000)\n",
      "\n",
      "Training Epoch: 6.98% (349/5000)\tBatch: 100.00% (20/20)\tLoss: 950.863953\n",
      "***Validation Results***\tLoss: 100.8252,\tAccuracy: 68.13% (6813/10000)\n",
      "\n",
      "Training Epoch: 7.00% (350/5000)\tBatch: 100.00% (20/20)\tLoss: 1009.039490\n",
      "***Validation Results***\tLoss: 102.8129,\tAccuracy: 68.29% (6829/10000)\n",
      "\n",
      "Training Epoch: 7.02% (351/5000)\tBatch: 100.00% (20/20)\tLoss: 989.107910\n",
      "***Validation Results***\tLoss: 105.0828,\tAccuracy: 68.37% (6837/10000)\n",
      "\n",
      "Training Epoch: 7.04% (352/5000)\tBatch: 100.00% (20/20)\tLoss: 976.079712\n",
      "***Validation Results***\tLoss: 107.6206,\tAccuracy: 68.45% (6845/10000)\n",
      "\n",
      "Training Epoch: 7.06% (353/5000)\tBatch: 100.00% (20/20)\tLoss: 1049.881470\n",
      "***Validation Results***\tLoss: 110.4236,\tAccuracy: 68.58% (6858/10000)\n",
      "\n",
      "Training Epoch: 7.08% (354/5000)\tBatch: 100.00% (20/20)\tLoss: 1020.541016\n",
      "***Validation Results***\tLoss: 113.4890,\tAccuracy: 68.70% (6870/10000)\n",
      "\n",
      "Training Epoch: 7.10% (355/5000)\tBatch: 100.00% (20/20)\tLoss: 1021.340088\n",
      "***Validation Results***\tLoss: 116.8081,\tAccuracy: 68.78% (6878/10000)\n",
      "\n",
      "Training Epoch: 7.12% (356/5000)\tBatch: 100.00% (20/20)\tLoss: 983.175293\n",
      "***Validation Results***\tLoss: 120.2795,\tAccuracy: 68.83% (6883/10000)\n",
      "\n",
      "Training Epoch: 7.14% (357/5000)\tBatch: 100.00% (20/20)\tLoss: 1027.310547\n",
      "***Validation Results***\tLoss: 123.7295,\tAccuracy: 68.81% (6881/10000)\n",
      "\n",
      "Training Epoch: 7.16% (358/5000)\tBatch: 100.00% (20/20)\tLoss: 1014.191284\n",
      "***Validation Results***\tLoss: 127.0097,\tAccuracy: 68.80% (6880/10000)\n",
      "\n",
      "Training Epoch: 7.18% (359/5000)\tBatch: 100.00% (20/20)\tLoss: 1071.661865\n",
      "***Validation Results***\tLoss: 130.1347,\tAccuracy: 68.83% (6883/10000)\n",
      "\n",
      "Training Epoch: 7.20% (360/5000)\tBatch: 100.00% (20/20)\tLoss: 1065.439697\n",
      "***Validation Results***\tLoss: 133.1147,\tAccuracy: 68.90% (6890/10000)\n",
      "\n",
      "Training Epoch: 7.22% (361/5000)\tBatch: 100.00% (20/20)\tLoss: 1113.097656\n",
      "***Validation Results***\tLoss: 135.9300,\tAccuracy: 68.92% (6892/10000)\n",
      "\n",
      "Training Epoch: 7.24% (362/5000)\tBatch: 100.00% (20/20)\tLoss: 1046.617432\n",
      "***Validation Results***\tLoss: 138.6415,\tAccuracy: 68.93% (6893/10000)\n",
      "\n",
      "Training Epoch: 7.26% (363/5000)\tBatch: 100.00% (20/20)\tLoss: 1076.393188\n",
      "***Validation Results***\tLoss: 141.2081,\tAccuracy: 68.95% (6895/10000)\n",
      "\n",
      "Training Epoch: 7.28% (364/5000)\tBatch: 100.00% (20/20)\tLoss: 1059.173828\n",
      "***Validation Results***\tLoss: 143.6468,\tAccuracy: 68.99% (6899/10000)\n",
      "\n",
      "Training Epoch: 7.30% (365/5000)\tBatch: 100.00% (20/20)\tLoss: 1113.360840\n",
      "***Validation Results***\tLoss: 145.9542,\tAccuracy: 68.99% (6899/10000)\n",
      "\n",
      "Training Epoch: 7.32% (366/5000)\tBatch: 100.00% (20/20)\tLoss: 1001.070862\n",
      "***Validation Results***\tLoss: 148.1443,\tAccuracy: 68.82% (6882/10000)\n",
      "\n",
      "Training Epoch: 7.34% (367/5000)\tBatch: 100.00% (20/20)\tLoss: 1032.566895\n",
      "***Validation Results***\tLoss: 150.1959,\tAccuracy: 68.81% (6881/10000)\n",
      "\n",
      "Training Epoch: 7.36% (368/5000)\tBatch: 100.00% (20/20)\tLoss: 1008.788818\n",
      "***Validation Results***\tLoss: 152.0693,\tAccuracy: 68.72% (6872/10000)\n",
      "\n",
      "Training Epoch: 7.38% (369/5000)\tBatch: 100.00% (20/20)\tLoss: 951.110596\n",
      "***Validation Results***\tLoss: 153.7599,\tAccuracy: 68.73% (6873/10000)\n",
      "\n",
      "Training Epoch: 7.40% (370/5000)\tBatch: 100.00% (20/20)\tLoss: 929.468933\n",
      "***Validation Results***\tLoss: 155.2557,\tAccuracy: 68.74% (6874/10000)\n",
      "\n",
      "Training Epoch: 7.42% (371/5000)\tBatch: 100.00% (20/20)\tLoss: 927.624695\n",
      "***Validation Results***\tLoss: 156.5328,\tAccuracy: 68.79% (6879/10000)\n",
      "\n",
      "Training Epoch: 7.44% (372/5000)\tBatch: 100.00% (20/20)\tLoss: 870.915344\n",
      "***Validation Results***\tLoss: 157.6055,\tAccuracy: 68.80% (6880/10000)\n",
      "\n",
      "Training Epoch: 7.46% (373/5000)\tBatch: 100.00% (20/20)\tLoss: 866.363708\n",
      "***Validation Results***\tLoss: 158.4876,\tAccuracy: 68.81% (6881/10000)\n",
      "\n",
      "Training Epoch: 7.48% (374/5000)\tBatch: 100.00% (20/20)\tLoss: 787.565125\n",
      "***Validation Results***\tLoss: 159.1450,\tAccuracy: 68.83% (6883/10000)\n",
      "\n",
      "Training Epoch: 7.50% (375/5000)\tBatch: 100.00% (20/20)\tLoss: 712.091614\n",
      "***Validation Results***\tLoss: 159.5815,\tAccuracy: 68.80% (6880/10000)\n",
      "\n",
      "Training Epoch: 7.52% (376/5000)\tBatch: 100.00% (20/20)\tLoss: 694.017151\n",
      "***Validation Results***\tLoss: 159.7896,\tAccuracy: 68.78% (6878/10000)\n",
      "\n",
      "Training Epoch: 7.54% (377/5000)\tBatch: 100.00% (20/20)\tLoss: 624.865173\n",
      "***Validation Results***\tLoss: 159.7979,\tAccuracy: 68.76% (6876/10000)\n",
      "\n",
      "Training Epoch: 7.56% (378/5000)\tBatch: 100.00% (20/20)\tLoss: 568.651184\n",
      "***Validation Results***\tLoss: 159.5900,\tAccuracy: 68.75% (6875/10000)\n",
      "\n",
      "Training Epoch: 7.58% (379/5000)\tBatch: 100.00% (20/20)\tLoss: 535.143738\n",
      "***Validation Results***\tLoss: 159.1334,\tAccuracy: 68.72% (6872/10000)\n",
      "\n",
      "Training Epoch: 7.60% (380/5000)\tBatch: 100.00% (20/20)\tLoss: 436.963440\n",
      "***Validation Results***\tLoss: 158.4598,\tAccuracy: 68.84% (6884/10000)\n",
      "\n",
      "Training Epoch: 7.62% (381/5000)\tBatch: 100.00% (20/20)\tLoss: 436.194061\n",
      "***Validation Results***\tLoss: 157.6300,\tAccuracy: 68.91% (6891/10000)\n",
      "\n",
      "Training Epoch: 7.64% (382/5000)\tBatch: 100.00% (20/20)\tLoss: 345.621063\n",
      "***Validation Results***\tLoss: 156.6573,\tAccuracy: 68.94% (6894/10000)\n",
      "\n",
      "Training Epoch: 7.66% (383/5000)\tBatch: 100.00% (20/20)\tLoss: 253.311630\n",
      "***Validation Results***\tLoss: 155.5208,\tAccuracy: 69.06% (6906/10000)\n",
      "\n",
      "Training Epoch: 7.68% (384/5000)\tBatch: 100.00% (20/20)\tLoss: 196.258804\n",
      "***Validation Results***\tLoss: 154.1370,\tAccuracy: 69.05% (6905/10000)\n",
      "\n",
      "Training Epoch: 7.70% (385/5000)\tBatch: 100.00% (20/20)\tLoss: 147.414551\n",
      "***Validation Results***\tLoss: 152.0655,\tAccuracy: 69.09% (6909/10000)\n",
      "\n",
      "Training Epoch: 7.72% (386/5000)\tBatch: 100.00% (20/20)\tLoss: 129.369080\n",
      "***Validation Results***\tLoss: 147.8720,\tAccuracy: 68.94% (6894/10000)\n",
      "\n",
      "Training Epoch: 7.74% (387/5000)\tBatch: 100.00% (20/20)\tLoss: 189.147842\n",
      "***Validation Results***\tLoss: 140.7890,\tAccuracy: 69.05% (6905/10000)\n",
      "\n",
      "Training Epoch: 7.76% (388/5000)\tBatch: 100.00% (20/20)\tLoss: 315.801727\n",
      "***Validation Results***\tLoss: 132.2453,\tAccuracy: 69.13% (6913/10000)\n",
      "\n",
      "Training Epoch: 7.78% (389/5000)\tBatch: 100.00% (20/20)\tLoss: 413.612030\n",
      "***Validation Results***\tLoss: 124.3271,\tAccuracy: 69.10% (6910/10000)\n",
      "\n",
      "Training Epoch: 7.80% (390/5000)\tBatch: 100.00% (20/20)\tLoss: 523.333130\n",
      "***Validation Results***\tLoss: 117.5733,\tAccuracy: 68.76% (6876/10000)\n",
      "\n",
      "Training Epoch: 7.82% (391/5000)\tBatch: 100.00% (20/20)\tLoss: 634.010193\n",
      "***Validation Results***\tLoss: 112.1200,\tAccuracy: 68.51% (6851/10000)\n",
      "\n",
      "Training Epoch: 7.84% (392/5000)\tBatch: 100.00% (20/20)\tLoss: 765.102112\n",
      "***Validation Results***\tLoss: 107.7866,\tAccuracy: 68.29% (6829/10000)\n",
      "\n",
      "Training Epoch: 7.86% (393/5000)\tBatch: 100.00% (20/20)\tLoss: 825.542908\n",
      "***Validation Results***\tLoss: 104.3806,\tAccuracy: 67.61% (6761/10000)\n",
      "\n",
      "Training Epoch: 7.88% (394/5000)\tBatch: 100.00% (20/20)\tLoss: 881.487793\n",
      "***Validation Results***\tLoss: 101.8039,\tAccuracy: 67.01% (6701/10000)\n",
      "\n",
      "Training Epoch: 7.90% (395/5000)\tBatch: 100.00% (20/20)\tLoss: 939.418335\n",
      "***Validation Results***\tLoss: 100.0975,\tAccuracy: 66.31% (6631/10000)\n",
      "\n",
      "Training Epoch: 7.92% (396/5000)\tBatch: 100.00% (20/20)\tLoss: 967.518127\n",
      "***Validation Results***\tLoss: 99.2104,\tAccuracy: 65.73% (6573/10000)\n",
      "\n",
      "Training Epoch: 7.94% (397/5000)\tBatch: 100.00% (20/20)\tLoss: 1056.251465\n",
      "***Validation Results***\tLoss: 99.0877,\tAccuracy: 65.39% (6539/10000)\n",
      "\n",
      "Training Epoch: 7.96% (398/5000)\tBatch: 100.00% (20/20)\tLoss: 1066.814575\n",
      "***Validation Results***\tLoss: 99.6699,\tAccuracy: 65.11% (6511/10000)\n",
      "\n",
      "Training Epoch: 7.98% (399/5000)\tBatch: 100.00% (20/20)\tLoss: 1076.271484\n",
      "***Validation Results***\tLoss: 101.0398,\tAccuracy: 64.59% (6459/10000)\n",
      "\n",
      "Training Epoch: 8.00% (400/5000)\tBatch: 100.00% (20/20)\tLoss: 1086.817017\n",
      "***Validation Results***\tLoss: 103.3381,\tAccuracy: 63.87% (6387/10000)\n",
      "\n",
      "Training Epoch: 8.02% (401/5000)\tBatch: 100.00% (20/20)\tLoss: 1059.441284\n",
      "***Validation Results***\tLoss: 106.6193,\tAccuracy: 62.70% (6270/10000)\n",
      "\n",
      "Training Epoch: 8.04% (402/5000)\tBatch: 100.00% (20/20)\tLoss: 1043.514404\n",
      "***Validation Results***\tLoss: 110.7140,\tAccuracy: 61.68% (6168/10000)\n",
      "\n",
      "Training Epoch: 8.06% (403/5000)\tBatch: 100.00% (20/20)\tLoss: 983.351135\n",
      "***Validation Results***\tLoss: 115.5871,\tAccuracy: 59.25% (5925/10000)\n",
      "\n",
      "Training Epoch: 8.08% (404/5000)\tBatch: 100.00% (20/20)\tLoss: 990.417908\n",
      "***Validation Results***\tLoss: 120.7679,\tAccuracy: 57.80% (5780/10000)\n",
      "\n",
      "Training Epoch: 8.10% (405/5000)\tBatch: 100.00% (20/20)\tLoss: 997.284668\n",
      "***Validation Results***\tLoss: 125.7980,\tAccuracy: 57.16% (5716/10000)\n",
      "\n",
      "Training Epoch: 8.12% (406/5000)\tBatch: 100.00% (20/20)\tLoss: 850.902466\n",
      "***Validation Results***\tLoss: 130.4887,\tAccuracy: 56.76% (5676/10000)\n",
      "\n",
      "Training Epoch: 8.14% (407/5000)\tBatch: 100.00% (20/20)\tLoss: 858.165222\n",
      "***Validation Results***\tLoss: 134.7898,\tAccuracy: 56.44% (5644/10000)\n",
      "\n",
      "Training Epoch: 8.16% (408/5000)\tBatch: 100.00% (20/20)\tLoss: 714.108643\n",
      "***Validation Results***\tLoss: 138.5426,\tAccuracy: 56.15% (5615/10000)\n",
      "\n",
      "Training Epoch: 8.18% (409/5000)\tBatch: 100.00% (20/20)\tLoss: 625.388184\n",
      "***Validation Results***\tLoss: 141.6534,\tAccuracy: 56.08% (5608/10000)\n",
      "\n",
      "Training Epoch: 8.20% (410/5000)\tBatch: 100.00% (20/20)\tLoss: 524.915771\n",
      "***Validation Results***\tLoss: 144.1008,\tAccuracy: 56.16% (5616/10000)\n",
      "\n",
      "Training Epoch: 8.22% (411/5000)\tBatch: 100.00% (20/20)\tLoss: 364.411530\n",
      "***Validation Results***\tLoss: 145.9006,\tAccuracy: 56.47% (5647/10000)\n",
      "\n",
      "Training Epoch: 8.24% (412/5000)\tBatch: 100.00% (20/20)\tLoss: 258.468781\n",
      "***Validation Results***\tLoss: 147.0204,\tAccuracy: 56.93% (5693/10000)\n",
      "\n",
      "Training Epoch: 8.26% (413/5000)\tBatch: 100.00% (20/20)\tLoss: 147.607300\n",
      "***Validation Results***\tLoss: 147.1268,\tAccuracy: 57.15% (5715/10000)\n",
      "\n",
      "Training Epoch: 8.28% (414/5000)\tBatch: 100.00% (20/20)\tLoss: 152.390747\n",
      "***Validation Results***\tLoss: 145.0150,\tAccuracy: 58.68% (5868/10000)\n",
      "\n",
      "Training Epoch: 8.30% (415/5000)\tBatch: 100.00% (20/20)\tLoss: 243.445099\n",
      "***Validation Results***\tLoss: 141.0474,\tAccuracy: 63.16% (6316/10000)\n",
      "\n",
      "Training Epoch: 8.32% (416/5000)\tBatch: 100.00% (20/20)\tLoss: 297.612183\n",
      "***Validation Results***\tLoss: 139.8602,\tAccuracy: 65.42% (6542/10000)\n",
      "\n",
      "Training Epoch: 8.34% (417/5000)\tBatch: 100.00% (20/20)\tLoss: 360.551056\n",
      "***Validation Results***\tLoss: 143.1401,\tAccuracy: 66.33% (6633/10000)\n",
      "\n",
      "Training Epoch: 8.36% (418/5000)\tBatch: 100.00% (20/20)\tLoss: 429.174347\n",
      "***Validation Results***\tLoss: 150.0350,\tAccuracy: 67.76% (6776/10000)\n",
      "\n",
      "Training Epoch: 8.38% (419/5000)\tBatch: 100.00% (20/20)\tLoss: 499.409790\n",
      "***Validation Results***\tLoss: 160.4658,\tAccuracy: 69.12% (6912/10000)\n",
      "\n",
      "Training Epoch: 8.40% (420/5000)\tBatch: 100.00% (20/20)\tLoss: 499.333496\n",
      "***Validation Results***\tLoss: 173.7915,\tAccuracy: 69.11% (6911/10000)\n",
      "\n",
      "Training Epoch: 8.42% (421/5000)\tBatch: 100.00% (20/20)\tLoss: 592.600403\n",
      "***Validation Results***\tLoss: 189.7179,\tAccuracy: 69.18% (6918/10000)\n",
      "\n",
      "Training Epoch: 8.44% (422/5000)\tBatch: 100.00% (20/20)\tLoss: 642.266602\n",
      "***Validation Results***\tLoss: 207.4008,\tAccuracy: 68.82% (6882/10000)\n",
      "\n",
      "Training Epoch: 8.46% (423/5000)\tBatch: 100.00% (20/20)\tLoss: 665.971680\n",
      "***Validation Results***\tLoss: 226.1654,\tAccuracy: 68.72% (6872/10000)\n",
      "\n",
      "Training Epoch: 8.48% (424/5000)\tBatch: 100.00% (20/20)\tLoss: 807.998962\n",
      "***Validation Results***\tLoss: 245.7579,\tAccuracy: 68.98% (6898/10000)\n",
      "\n",
      "Training Epoch: 8.50% (425/5000)\tBatch: 100.00% (20/20)\tLoss: 787.048279\n",
      "***Validation Results***\tLoss: 265.9133,\tAccuracy: 69.04% (6904/10000)\n",
      "\n",
      "Training Epoch: 8.52% (426/5000)\tBatch: 100.00% (20/20)\tLoss: 770.756714\n",
      "***Validation Results***\tLoss: 286.4486,\tAccuracy: 68.37% (6837/10000)\n",
      "\n",
      "Training Epoch: 8.54% (427/5000)\tBatch: 100.00% (20/20)\tLoss: 806.720886\n",
      "***Validation Results***\tLoss: 308.1814,\tAccuracy: 67.14% (6714/10000)\n",
      "\n",
      "Training Epoch: 8.56% (428/5000)\tBatch: 100.00% (20/20)\tLoss: 875.778687\n",
      "***Validation Results***\tLoss: 329.8795,\tAccuracy: 67.13% (6713/10000)\n",
      "\n",
      "Training Epoch: 8.58% (429/5000)\tBatch: 100.00% (20/20)\tLoss: 886.646484\n",
      "***Validation Results***\tLoss: 351.4362,\tAccuracy: 67.02% (6702/10000)\n",
      "\n",
      "Training Epoch: 8.60% (430/5000)\tBatch: 100.00% (20/20)\tLoss: 951.138367\n",
      "***Validation Results***\tLoss: 373.0125,\tAccuracy: 66.89% (6689/10000)\n",
      "\n",
      "Training Epoch: 8.62% (431/5000)\tBatch: 100.00% (20/20)\tLoss: 939.781128\n",
      "***Validation Results***\tLoss: 394.5891,\tAccuracy: 66.96% (6696/10000)\n",
      "\n",
      "Training Epoch: 8.64% (432/5000)\tBatch: 100.00% (20/20)\tLoss: 976.908936\n",
      "***Validation Results***\tLoss: 416.1623,\tAccuracy: 66.94% (6694/10000)\n",
      "\n",
      "Training Epoch: 8.66% (433/5000)\tBatch: 100.00% (20/20)\tLoss: 1065.041870\n",
      "***Validation Results***\tLoss: 437.6881,\tAccuracy: 66.82% (6682/10000)\n",
      "\n",
      "Training Epoch: 8.68% (434/5000)\tBatch: 100.00% (20/20)\tLoss: 982.955383\n",
      "***Validation Results***\tLoss: 459.1514,\tAccuracy: 66.74% (6674/10000)\n",
      "\n",
      "Training Epoch: 8.70% (435/5000)\tBatch: 100.00% (20/20)\tLoss: 1039.799072\n",
      "***Validation Results***\tLoss: 480.5410,\tAccuracy: 66.65% (6665/10000)\n",
      "\n",
      "Training Epoch: 8.72% (436/5000)\tBatch: 100.00% (20/20)\tLoss: 1035.074951\n",
      "***Validation Results***\tLoss: 501.8753,\tAccuracy: 66.59% (6659/10000)\n",
      "\n",
      "Training Epoch: 8.74% (437/5000)\tBatch: 100.00% (20/20)\tLoss: 1004.475586\n",
      "***Validation Results***\tLoss: 523.1568,\tAccuracy: 66.58% (6658/10000)\n",
      "\n",
      "Training Epoch: 8.76% (438/5000)\tBatch: 100.00% (20/20)\tLoss: 1094.186279\n",
      "***Validation Results***\tLoss: 544.3425,\tAccuracy: 66.55% (6655/10000)\n",
      "\n",
      "Training Epoch: 8.78% (439/5000)\tBatch: 100.00% (20/20)\tLoss: 1105.645630\n",
      "***Validation Results***\tLoss: 565.4274,\tAccuracy: 66.51% (6651/10000)\n",
      "\n",
      "Training Epoch: 8.80% (440/5000)\tBatch: 100.00% (20/20)\tLoss: 1085.115967\n",
      "***Validation Results***\tLoss: 586.4395,\tAccuracy: 66.53% (6653/10000)\n",
      "\n",
      "Training Epoch: 8.82% (441/5000)\tBatch: 100.00% (20/20)\tLoss: 1030.889404\n",
      "***Validation Results***\tLoss: 607.4143,\tAccuracy: 66.52% (6652/10000)\n",
      "\n",
      "Training Epoch: 8.84% (442/5000)\tBatch: 100.00% (20/20)\tLoss: 1051.205322\n",
      "***Validation Results***\tLoss: 628.2850,\tAccuracy: 66.50% (6650/10000)\n",
      "\n",
      "Training Epoch: 8.86% (443/5000)\tBatch: 100.00% (20/20)\tLoss: 1037.505249\n",
      "***Validation Results***\tLoss: 649.0205,\tAccuracy: 66.52% (6652/10000)\n",
      "\n",
      "Training Epoch: 8.88% (444/5000)\tBatch: 100.00% (20/20)\tLoss: 1068.604492\n",
      "***Validation Results***\tLoss: 669.4862,\tAccuracy: 66.44% (6644/10000)\n",
      "\n",
      "Training Epoch: 8.90% (445/5000)\tBatch: 100.00% (20/20)\tLoss: 1022.306030\n",
      "***Validation Results***\tLoss: 689.6608,\tAccuracy: 66.37% (6637/10000)\n",
      "\n",
      "Training Epoch: 8.92% (446/5000)\tBatch: 100.00% (20/20)\tLoss: 1030.448364\n",
      "***Validation Results***\tLoss: 709.5057,\tAccuracy: 66.19% (6619/10000)\n",
      "\n",
      "Training Epoch: 8.94% (447/5000)\tBatch: 100.00% (20/20)\tLoss: 993.218506\n",
      "***Validation Results***\tLoss: 728.9015,\tAccuracy: 66.18% (6618/10000)\n",
      "\n",
      "Training Epoch: 8.96% (448/5000)\tBatch: 100.00% (20/20)\tLoss: 1009.137817\n",
      "***Validation Results***\tLoss: 747.7657,\tAccuracy: 66.05% (6605/10000)\n",
      "\n",
      "Training Epoch: 8.98% (449/5000)\tBatch: 100.00% (20/20)\tLoss: 905.282532\n",
      "***Validation Results***\tLoss: 765.9456,\tAccuracy: 66.01% (6601/10000)\n",
      "\n",
      "Training Epoch: 9.00% (450/5000)\tBatch: 100.00% (20/20)\tLoss: 896.712585\n",
      "***Validation Results***\tLoss: 783.2917,\tAccuracy: 65.96% (6596/10000)\n",
      "\n",
      "Training Epoch: 9.02% (451/5000)\tBatch: 100.00% (20/20)\tLoss: 829.178772\n",
      "***Validation Results***\tLoss: 799.6725,\tAccuracy: 65.93% (6593/10000)\n",
      "\n",
      "Training Epoch: 9.04% (452/5000)\tBatch: 100.00% (20/20)\tLoss: 875.085876\n",
      "***Validation Results***\tLoss: 814.7208,\tAccuracy: 65.89% (6589/10000)\n",
      "\n",
      "Training Epoch: 9.06% (453/5000)\tBatch: 100.00% (20/20)\tLoss: 781.514954\n",
      "***Validation Results***\tLoss: 827.4602,\tAccuracy: 65.80% (6580/10000)\n",
      "\n",
      "Training Epoch: 9.08% (454/5000)\tBatch: 100.00% (20/20)\tLoss: 810.042847\n",
      "***Validation Results***\tLoss: 835.7258,\tAccuracy: 65.71% (6571/10000)\n",
      "\n",
      "Training Epoch: 9.10% (455/5000)\tBatch: 100.00% (20/20)\tLoss: 824.995300\n",
      "***Validation Results***\tLoss: 837.7576,\tAccuracy: 65.70% (6570/10000)\n",
      "\n",
      "Training Epoch: 9.12% (456/5000)\tBatch: 100.00% (20/20)\tLoss: 883.804688\n",
      "***Validation Results***\tLoss: 832.9815,\tAccuracy: 65.71% (6571/10000)\n",
      "\n",
      "Training Epoch: 9.14% (457/5000)\tBatch: 100.00% (20/20)\tLoss: 769.526550\n",
      "***Validation Results***\tLoss: 821.1893,\tAccuracy: 65.83% (6583/10000)\n",
      "\n",
      "Training Epoch: 9.16% (458/5000)\tBatch: 100.00% (20/20)\tLoss: 808.278503\n",
      "***Validation Results***\tLoss: 802.4154,\tAccuracy: 65.89% (6589/10000)\n",
      "\n",
      "Training Epoch: 9.18% (459/5000)\tBatch: 100.00% (20/20)\tLoss: 715.747986\n",
      "***Validation Results***\tLoss: 776.7105,\tAccuracy: 65.96% (6596/10000)\n",
      "\n",
      "Training Epoch: 9.20% (460/5000)\tBatch: 100.00% (20/20)\tLoss: 754.131287\n",
      "***Validation Results***\tLoss: 744.1285,\tAccuracy: 66.04% (6604/10000)\n",
      "\n",
      "Training Epoch: 9.22% (461/5000)\tBatch: 100.00% (20/20)\tLoss: 656.949707\n",
      "***Validation Results***\tLoss: 704.7714,\tAccuracy: 66.19% (6619/10000)\n",
      "\n",
      "Training Epoch: 9.24% (462/5000)\tBatch: 100.00% (20/20)\tLoss: 611.901550\n",
      "***Validation Results***\tLoss: 658.7132,\tAccuracy: 66.38% (6638/10000)\n",
      "\n",
      "Training Epoch: 9.26% (463/5000)\tBatch: 100.00% (20/20)\tLoss: 576.497070\n",
      "***Validation Results***\tLoss: 605.9831,\tAccuracy: 66.44% (6644/10000)\n",
      "\n",
      "Training Epoch: 9.28% (464/5000)\tBatch: 100.00% (20/20)\tLoss: 482.504761\n",
      "***Validation Results***\tLoss: 546.6537,\tAccuracy: 66.49% (6649/10000)\n",
      "\n",
      "Training Epoch: 9.30% (465/5000)\tBatch: 100.00% (20/20)\tLoss: 454.909821\n",
      "***Validation Results***\tLoss: 480.8470,\tAccuracy: 66.67% (6667/10000)\n",
      "\n",
      "Training Epoch: 9.32% (466/5000)\tBatch: 100.00% (20/20)\tLoss: 365.933258\n",
      "***Validation Results***\tLoss: 409.0731,\tAccuracy: 66.95% (6695/10000)\n",
      "\n",
      "Training Epoch: 9.34% (467/5000)\tBatch: 100.00% (20/20)\tLoss: 322.038635\n",
      "***Validation Results***\tLoss: 332.1023,\tAccuracy: 67.19% (6719/10000)\n",
      "\n",
      "Training Epoch: 9.36% (468/5000)\tBatch: 100.00% (20/20)\tLoss: 250.250870\n",
      "***Validation Results***\tLoss: 256.8207,\tAccuracy: 68.90% (6890/10000)\n",
      "\n",
      "Training Epoch: 9.38% (469/5000)\tBatch: 100.00% (20/20)\tLoss: 204.371582\n",
      "***Validation Results***\tLoss: 195.2430,\tAccuracy: 68.76% (6876/10000)\n",
      "\n",
      "Training Epoch: 9.40% (470/5000)\tBatch: 100.00% (20/20)\tLoss: 268.510773\n",
      "***Validation Results***\tLoss: 200.4246,\tAccuracy: 58.94% (5894/10000)\n",
      "\n",
      "Training Epoch: 9.42% (471/5000)\tBatch: 100.00% (20/20)\tLoss: 381.952393\n",
      "***Validation Results***\tLoss: 319.6514,\tAccuracy: 47.83% (4783/10000)\n",
      "\n",
      "Training Epoch: 9.44% (472/5000)\tBatch: 100.00% (20/20)\tLoss: 475.320190\n",
      "***Validation Results***\tLoss: 470.9888,\tAccuracy: 42.56% (4256/10000)\n",
      "\n",
      "Training Epoch: 9.46% (473/5000)\tBatch: 100.00% (20/20)\tLoss: 595.358765\n",
      "***Validation Results***\tLoss: 618.5115,\tAccuracy: 40.43% (4043/10000)\n",
      "\n",
      "Training Epoch: 9.48% (474/5000)\tBatch: 100.00% (20/20)\tLoss: 723.322388\n",
      "***Validation Results***\tLoss: 749.5223,\tAccuracy: 38.60% (3860/10000)\n",
      "\n",
      "Training Epoch: 9.50% (475/5000)\tBatch: 100.00% (20/20)\tLoss: 833.461609\n",
      "***Validation Results***\tLoss: 859.3006,\tAccuracy: 37.75% (3775/10000)\n",
      "\n",
      "Training Epoch: 9.52% (476/5000)\tBatch: 100.00% (20/20)\tLoss: 949.944824\n",
      "***Validation Results***\tLoss: 945.9419,\tAccuracy: 37.24% (3724/10000)\n",
      "\n",
      "Training Epoch: 9.54% (477/5000)\tBatch: 100.00% (20/20)\tLoss: 1030.268066\n",
      "***Validation Results***\tLoss: 1008.5214,\tAccuracy: 36.88% (3688/10000)\n",
      "\n",
      "Training Epoch: 9.56% (478/5000)\tBatch: 100.00% (20/20)\tLoss: 982.055237\n",
      "***Validation Results***\tLoss: 1046.3678,\tAccuracy: 36.80% (3680/10000)\n",
      "\n",
      "Training Epoch: 9.58% (479/5000)\tBatch: 100.00% (20/20)\tLoss: 1043.873779\n",
      "***Validation Results***\tLoss: 1059.1915,\tAccuracy: 36.74% (3674/10000)\n",
      "\n",
      "Training Epoch: 9.60% (480/5000)\tBatch: 100.00% (20/20)\tLoss: 1055.711670\n",
      "***Validation Results***\tLoss: 1046.7815,\tAccuracy: 36.82% (3682/10000)\n",
      "\n",
      "Training Epoch: 9.62% (481/5000)\tBatch: 100.00% (20/20)\tLoss: 942.125366\n",
      "***Validation Results***\tLoss: 1009.5330,\tAccuracy: 36.91% (3691/10000)\n",
      "\n",
      "Training Epoch: 9.64% (482/5000)\tBatch: 100.00% (20/20)\tLoss: 1008.083191\n",
      "***Validation Results***\tLoss: 949.0528,\tAccuracy: 37.32% (3732/10000)\n",
      "\n",
      "Training Epoch: 9.66% (483/5000)\tBatch: 100.00% (20/20)\tLoss: 904.534668\n",
      "***Validation Results***\tLoss: 869.6743,\tAccuracy: 37.80% (3780/10000)\n",
      "\n",
      "Training Epoch: 9.68% (484/5000)\tBatch: 100.00% (20/20)\tLoss: 1014.052551\n",
      "***Validation Results***\tLoss: 781.1370,\tAccuracy: 38.45% (3845/10000)\n",
      "\n",
      "Training Epoch: 9.70% (485/5000)\tBatch: 100.00% (20/20)\tLoss: 932.661255\n",
      "***Validation Results***\tLoss: 690.9068,\tAccuracy: 39.59% (3959/10000)\n",
      "\n",
      "Training Epoch: 9.72% (486/5000)\tBatch: 100.00% (20/20)\tLoss: 1016.734070\n",
      "***Validation Results***\tLoss: 601.7228,\tAccuracy: 40.82% (4082/10000)\n",
      "\n",
      "Training Epoch: 9.74% (487/5000)\tBatch: 100.00% (20/20)\tLoss: 1092.399536\n",
      "***Validation Results***\tLoss: 514.5244,\tAccuracy: 42.00% (4200/10000)\n",
      "\n",
      "Training Epoch: 9.76% (488/5000)\tBatch: 100.00% (20/20)\tLoss: 1040.890747\n",
      "***Validation Results***\tLoss: 430.2086,\tAccuracy: 43.96% (4396/10000)\n",
      "\n",
      "Training Epoch: 9.78% (489/5000)\tBatch: 100.00% (20/20)\tLoss: 1047.112427\n",
      "***Validation Results***\tLoss: 349.8582,\tAccuracy: 46.84% (4684/10000)\n",
      "\n",
      "Training Epoch: 9.80% (490/5000)\tBatch: 100.00% (20/20)\tLoss: 1041.014526\n",
      "***Validation Results***\tLoss: 276.2109,\tAccuracy: 51.33% (5133/10000)\n",
      "\n",
      "Training Epoch: 9.82% (491/5000)\tBatch: 100.00% (20/20)\tLoss: 1007.821228\n",
      "***Validation Results***\tLoss: 218.0028,\tAccuracy: 57.26% (5726/10000)\n",
      "\n",
      "Training Epoch: 9.84% (492/5000)\tBatch: 100.00% (20/20)\tLoss: 928.233643\n",
      "***Validation Results***\tLoss: 185.2399,\tAccuracy: 65.36% (6536/10000)\n",
      "\n",
      "Training Epoch: 9.86% (493/5000)\tBatch: 100.00% (20/20)\tLoss: 925.551331\n",
      "***Validation Results***\tLoss: 192.0697,\tAccuracy: 68.20% (6820/10000)\n",
      "\n",
      "Training Epoch: 9.88% (494/5000)\tBatch: 100.00% (20/20)\tLoss: 821.515991\n",
      "***Validation Results***\tLoss: 216.0548,\tAccuracy: 69.18% (6918/10000)\n",
      "\n",
      "Training Epoch: 9.90% (495/5000)\tBatch: 100.00% (20/20)\tLoss: 730.497681\n",
      "***Validation Results***\tLoss: 247.7942,\tAccuracy: 69.13% (6913/10000)\n",
      "\n",
      "Training Epoch: 9.92% (496/5000)\tBatch: 100.00% (20/20)\tLoss: 672.410767\n",
      "***Validation Results***\tLoss: 282.9904,\tAccuracy: 69.04% (6904/10000)\n",
      "\n",
      "Training Epoch: 9.94% (497/5000)\tBatch: 100.00% (20/20)\tLoss: 604.262390\n",
      "***Validation Results***\tLoss: 318.8937,\tAccuracy: 69.15% (6915/10000)\n",
      "\n",
      "Training Epoch: 9.96% (498/5000)\tBatch: 100.00% (20/20)\tLoss: 469.172882\n",
      "***Validation Results***\tLoss: 354.4913,\tAccuracy: 67.21% (6721/10000)\n",
      "\n",
      "Training Epoch: 9.98% (499/5000)\tBatch: 100.00% (20/20)\tLoss: 410.713989\n",
      "***Validation Results***\tLoss: 388.3243,\tAccuracy: 67.14% (6714/10000)\n",
      "\n",
      "Training Epoch: 10.00% (500/5000)\tBatch: 100.00% (20/20)\tLoss: 370.149445\n",
      "***Validation Results***\tLoss: 417.0530,\tAccuracy: 67.04% (6704/10000)\n",
      "\n",
      "Training Epoch: 10.02% (501/5000)\tBatch: 100.00% (20/20)\tLoss: 446.415955\n",
      "***Validation Results***\tLoss: 438.7238,\tAccuracy: 66.95% (6695/10000)\n",
      "\n",
      "Training Epoch: 10.04% (502/5000)\tBatch: 100.00% (20/20)\tLoss: 506.234619\n",
      "***Validation Results***\tLoss: 452.7156,\tAccuracy: 66.92% (6692/10000)\n",
      "\n",
      "Training Epoch: 10.06% (503/5000)\tBatch: 100.00% (20/20)\tLoss: 420.523010\n",
      "***Validation Results***\tLoss: 459.1616,\tAccuracy: 66.90% (6690/10000)\n",
      "\n",
      "Training Epoch: 10.08% (504/5000)\tBatch: 100.00% (20/20)\tLoss: 415.214508\n",
      "***Validation Results***\tLoss: 458.4891,\tAccuracy: 66.89% (6689/10000)\n",
      "\n",
      "Training Epoch: 10.10% (505/5000)\tBatch: 100.00% (20/20)\tLoss: 450.244843\n",
      "***Validation Results***\tLoss: 451.4295,\tAccuracy: 66.94% (6694/10000)\n",
      "\n",
      "Training Epoch: 10.12% (506/5000)\tBatch: 100.00% (20/20)\tLoss: 446.605713\n",
      "***Validation Results***\tLoss: 439.1790,\tAccuracy: 66.98% (6698/10000)\n",
      "\n",
      "Training Epoch: 10.14% (507/5000)\tBatch: 100.00% (20/20)\tLoss: 477.703918\n",
      "***Validation Results***\tLoss: 424.4145,\tAccuracy: 67.11% (6711/10000)\n",
      "\n",
      "Training Epoch: 10.16% (508/5000)\tBatch: 100.00% (20/20)\tLoss: 572.914062\n",
      "***Validation Results***\tLoss: 409.4902,\tAccuracy: 67.13% (6713/10000)\n",
      "\n",
      "Training Epoch: 10.18% (509/5000)\tBatch: 100.00% (20/20)\tLoss: 619.295349\n",
      "***Validation Results***\tLoss: 395.1464,\tAccuracy: 67.17% (6717/10000)\n",
      "\n",
      "Training Epoch: 10.20% (510/5000)\tBatch: 100.00% (20/20)\tLoss: 678.102295\n",
      "***Validation Results***\tLoss: 381.5545,\tAccuracy: 67.22% (6722/10000)\n",
      "\n",
      "Training Epoch: 10.22% (511/5000)\tBatch: 100.00% (20/20)\tLoss: 672.191650\n",
      "***Validation Results***\tLoss: 368.8313,\tAccuracy: 67.67% (6767/10000)\n",
      "\n",
      "Training Epoch: 10.24% (512/5000)\tBatch: 100.00% (20/20)\tLoss: 809.514954\n",
      "***Validation Results***\tLoss: 357.2508,\tAccuracy: 68.62% (6862/10000)\n",
      "\n",
      "Training Epoch: 10.26% (513/5000)\tBatch: 100.00% (20/20)\tLoss: 887.796265\n",
      "***Validation Results***\tLoss: 346.6398,\tAccuracy: 69.14% (6914/10000)\n",
      "\n",
      "Training Epoch: 10.28% (514/5000)\tBatch: 100.00% (20/20)\tLoss: 825.107849\n",
      "***Validation Results***\tLoss: 336.7781,\tAccuracy: 69.32% (6932/10000)\n",
      "\n",
      "Training Epoch: 10.30% (515/5000)\tBatch: 100.00% (20/20)\tLoss: 897.639404\n",
      "***Validation Results***\tLoss: 327.6452,\tAccuracy: 69.25% (6925/10000)\n",
      "\n",
      "Training Epoch: 10.32% (516/5000)\tBatch: 100.00% (20/20)\tLoss: 998.644775\n",
      "***Validation Results***\tLoss: 319.2533,\tAccuracy: 69.03% (6903/10000)\n",
      "\n",
      "Training Epoch: 10.34% (517/5000)\tBatch: 100.00% (20/20)\tLoss: 927.250183\n",
      "***Validation Results***\tLoss: 311.5437,\tAccuracy: 68.92% (6892/10000)\n",
      "\n",
      "Training Epoch: 10.36% (518/5000)\tBatch: 100.00% (20/20)\tLoss: 928.758606\n",
      "***Validation Results***\tLoss: 304.5342,\tAccuracy: 68.86% (6886/10000)\n",
      "\n",
      "Training Epoch: 10.38% (519/5000)\tBatch: 100.00% (20/20)\tLoss: 1010.739258\n",
      "***Validation Results***\tLoss: 298.2662,\tAccuracy: 69.00% (6900/10000)\n",
      "\n",
      "Training Epoch: 10.40% (520/5000)\tBatch: 100.00% (20/20)\tLoss: 1050.492310\n",
      "***Validation Results***\tLoss: 292.6651,\tAccuracy: 68.75% (6875/10000)\n",
      "\n",
      "Training Epoch: 10.42% (521/5000)\tBatch: 100.00% (20/20)\tLoss: 1079.928833\n",
      "***Validation Results***\tLoss: 287.7115,\tAccuracy: 69.04% (6904/10000)\n",
      "\n",
      "Training Epoch: 10.44% (522/5000)\tBatch: 100.00% (20/20)\tLoss: 1126.889160\n",
      "***Validation Results***\tLoss: 283.4625,\tAccuracy: 69.21% (6921/10000)\n",
      "\n",
      "Training Epoch: 10.46% (523/5000)\tBatch: 100.00% (20/20)\tLoss: 1133.481934\n",
      "***Validation Results***\tLoss: 279.9260,\tAccuracy: 69.37% (6937/10000)\n",
      "\n",
      "Training Epoch: 10.48% (524/5000)\tBatch: 100.00% (20/20)\tLoss: 1154.150635\n",
      "***Validation Results***\tLoss: 277.0825,\tAccuracy: 69.42% (6942/10000)\n",
      "\n",
      "Training Epoch: 10.50% (525/5000)\tBatch: 100.00% (20/20)\tLoss: 1191.604492\n",
      "***Validation Results***\tLoss: 274.9430,\tAccuracy: 69.39% (6939/10000)\n",
      "\n",
      "Training Epoch: 10.52% (526/5000)\tBatch: 100.00% (20/20)\tLoss: 1234.851074\n",
      "***Validation Results***\tLoss: 273.5371,\tAccuracy: 69.37% (6937/10000)\n",
      "\n",
      "Training Epoch: 10.54% (527/5000)\tBatch: 100.00% (20/20)\tLoss: 1146.769653\n",
      "***Validation Results***\tLoss: 272.8470,\tAccuracy: 69.43% (6943/10000)\n",
      "\n",
      "Training Epoch: 10.56% (528/5000)\tBatch: 100.00% (20/20)\tLoss: 1111.169678\n",
      "***Validation Results***\tLoss: 272.8955,\tAccuracy: 69.36% (6936/10000)\n",
      "\n",
      "Training Epoch: 10.58% (529/5000)\tBatch: 100.00% (20/20)\tLoss: 1177.060791\n",
      "***Validation Results***\tLoss: 273.7114,\tAccuracy: 69.42% (6942/10000)\n",
      "\n",
      "Training Epoch: 10.60% (530/5000)\tBatch: 100.00% (20/20)\tLoss: 1246.029785\n",
      "***Validation Results***\tLoss: 275.3247,\tAccuracy: 69.43% (6943/10000)\n",
      "\n",
      "Training Epoch: 10.62% (531/5000)\tBatch: 100.00% (20/20)\tLoss: 1173.481567\n",
      "***Validation Results***\tLoss: 277.7564,\tAccuracy: 69.35% (6935/10000)\n",
      "\n",
      "Training Epoch: 10.64% (532/5000)\tBatch: 100.00% (20/20)\tLoss: 1183.636597\n",
      "***Validation Results***\tLoss: 281.0395,\tAccuracy: 69.20% (6920/10000)\n",
      "\n",
      "Training Epoch: 10.66% (533/5000)\tBatch: 100.00% (20/20)\tLoss: 1212.987061\n",
      "***Validation Results***\tLoss: 285.1559,\tAccuracy: 69.02% (6902/10000)\n",
      "\n",
      "Training Epoch: 10.68% (534/5000)\tBatch: 100.00% (20/20)\tLoss: 1041.133423\n",
      "***Validation Results***\tLoss: 290.0846,\tAccuracy: 68.80% (6880/10000)\n",
      "\n",
      "Training Epoch: 10.70% (535/5000)\tBatch: 100.00% (20/20)\tLoss: 1105.218384\n",
      "***Validation Results***\tLoss: 295.7749,\tAccuracy: 69.08% (6908/10000)\n",
      "\n",
      "Training Epoch: 10.72% (536/5000)\tBatch: 100.00% (20/20)\tLoss: 1090.159668\n",
      "***Validation Results***\tLoss: 302.1681,\tAccuracy: 68.88% (6888/10000)\n",
      "\n",
      "Training Epoch: 10.74% (537/5000)\tBatch: 100.00% (20/20)\tLoss: 1009.315674\n",
      "***Validation Results***\tLoss: 309.2704,\tAccuracy: 68.97% (6897/10000)\n",
      "\n",
      "Training Epoch: 10.76% (538/5000)\tBatch: 100.00% (20/20)\tLoss: 980.077942\n",
      "***Validation Results***\tLoss: 316.9370,\tAccuracy: 69.01% (6901/10000)\n",
      "\n",
      "Training Epoch: 10.78% (539/5000)\tBatch: 100.00% (20/20)\tLoss: 978.537292\n",
      "***Validation Results***\tLoss: 325.2193,\tAccuracy: 69.25% (6925/10000)\n",
      "\n",
      "Training Epoch: 10.80% (540/5000)\tBatch: 100.00% (20/20)\tLoss: 895.772034\n",
      "***Validation Results***\tLoss: 333.9666,\tAccuracy: 69.33% (6933/10000)\n",
      "\n",
      "Training Epoch: 10.82% (541/5000)\tBatch: 100.00% (20/20)\tLoss: 837.239441\n",
      "***Validation Results***\tLoss: 342.9545,\tAccuracy: 69.21% (6921/10000)\n",
      "\n",
      "Training Epoch: 10.84% (542/5000)\tBatch: 100.00% (20/20)\tLoss: 790.291077\n",
      "***Validation Results***\tLoss: 352.1327,\tAccuracy: 68.63% (6863/10000)\n",
      "\n",
      "Training Epoch: 10.86% (543/5000)\tBatch: 100.00% (20/20)\tLoss: 778.891663\n",
      "***Validation Results***\tLoss: 361.4084,\tAccuracy: 68.03% (6803/10000)\n",
      "\n",
      "Training Epoch: 10.88% (544/5000)\tBatch: 100.00% (20/20)\tLoss: 621.822632\n",
      "***Validation Results***\tLoss: 370.7758,\tAccuracy: 67.35% (6735/10000)\n",
      "\n",
      "Training Epoch: 10.90% (545/5000)\tBatch: 100.00% (20/20)\tLoss: 620.659851\n",
      "***Validation Results***\tLoss: 379.9470,\tAccuracy: 67.16% (6716/10000)\n",
      "\n",
      "Training Epoch: 10.92% (546/5000)\tBatch: 100.00% (20/20)\tLoss: 558.277893\n",
      "***Validation Results***\tLoss: 388.6024,\tAccuracy: 67.23% (6723/10000)\n",
      "\n",
      "Training Epoch: 10.94% (547/5000)\tBatch: 100.00% (20/20)\tLoss: 517.708557\n",
      "***Validation Results***\tLoss: 396.5139,\tAccuracy: 67.19% (6719/10000)\n",
      "\n",
      "Training Epoch: 10.96% (548/5000)\tBatch: 100.00% (20/20)\tLoss: 462.090851\n",
      "***Validation Results***\tLoss: 403.4384,\tAccuracy: 67.08% (6708/10000)\n",
      "\n",
      "Training Epoch: 10.98% (549/5000)\tBatch: 100.00% (20/20)\tLoss: 403.167053\n",
      "***Validation Results***\tLoss: 408.6362,\tAccuracy: 67.10% (6710/10000)\n",
      "\n",
      "Training Epoch: 11.00% (550/5000)\tBatch: 100.00% (20/20)\tLoss: 388.928406\n",
      "***Validation Results***\tLoss: 409.9958,\tAccuracy: 67.08% (6708/10000)\n",
      "\n",
      "Training Epoch: 11.02% (551/5000)\tBatch: 100.00% (20/20)\tLoss: 361.086517\n",
      "***Validation Results***\tLoss: 405.7446,\tAccuracy: 67.08% (6708/10000)\n",
      "\n",
      "Training Epoch: 11.04% (552/5000)\tBatch: 100.00% (20/20)\tLoss: 366.240662\n",
      "***Validation Results***\tLoss: 395.4795,\tAccuracy: 67.05% (6705/10000)\n",
      "\n",
      "Training Epoch: 11.06% (553/5000)\tBatch: 100.00% (20/20)\tLoss: 427.561676\n",
      "***Validation Results***\tLoss: 379.2296,\tAccuracy: 67.19% (6719/10000)\n",
      "\n",
      "Training Epoch: 11.08% (554/5000)\tBatch: 100.00% (20/20)\tLoss: 362.250702\n",
      "***Validation Results***\tLoss: 357.2822,\tAccuracy: 67.22% (6722/10000)\n",
      "\n",
      "Training Epoch: 11.10% (555/5000)\tBatch: 100.00% (20/20)\tLoss: 338.971680\n",
      "***Validation Results***\tLoss: 330.4858,\tAccuracy: 68.06% (6806/10000)\n",
      "\n",
      "Training Epoch: 11.12% (556/5000)\tBatch: 100.00% (20/20)\tLoss: 419.918488\n",
      "***Validation Results***\tLoss: 301.2520,\tAccuracy: 69.19% (6919/10000)\n",
      "\n",
      "Training Epoch: 11.14% (557/5000)\tBatch: 100.00% (20/20)\tLoss: 536.921021\n",
      "***Validation Results***\tLoss: 271.2542,\tAccuracy: 69.01% (6901/10000)\n",
      "\n",
      "Training Epoch: 11.16% (558/5000)\tBatch: 100.00% (20/20)\tLoss: 567.246094\n",
      "***Validation Results***\tLoss: 241.7846,\tAccuracy: 69.22% (6922/10000)\n",
      "\n",
      "Training Epoch: 11.18% (559/5000)\tBatch: 100.00% (20/20)\tLoss: 735.981812\n",
      "***Validation Results***\tLoss: 213.6676,\tAccuracy: 69.45% (6945/10000)\n",
      "\n",
      "Training Epoch: 11.20% (560/5000)\tBatch: 100.00% (20/20)\tLoss: 765.585510\n",
      "***Validation Results***\tLoss: 187.9675,\tAccuracy: 69.22% (6922/10000)\n",
      "\n",
      "Training Epoch: 11.22% (561/5000)\tBatch: 100.00% (20/20)\tLoss: 828.210205\n",
      "***Validation Results***\tLoss: 166.5739,\tAccuracy: 68.78% (6878/10000)\n",
      "\n",
      "Training Epoch: 11.24% (562/5000)\tBatch: 100.00% (20/20)\tLoss: 908.402039\n",
      "***Validation Results***\tLoss: 152.5118,\tAccuracy: 67.26% (6726/10000)\n",
      "\n",
      "Training Epoch: 11.26% (563/5000)\tBatch: 100.00% (20/20)\tLoss: 983.320923\n",
      "***Validation Results***\tLoss: 154.7930,\tAccuracy: 62.87% (6287/10000)\n",
      "\n",
      "Training Epoch: 11.28% (564/5000)\tBatch: 100.00% (20/20)\tLoss: 946.901184\n",
      "***Validation Results***\tLoss: 184.6412,\tAccuracy: 57.49% (5749/10000)\n",
      "\n",
      "Training Epoch: 11.30% (565/5000)\tBatch: 100.00% (20/20)\tLoss: 965.641174\n",
      "***Validation Results***\tLoss: 231.5148,\tAccuracy: 52.43% (5243/10000)\n",
      "\n",
      "Training Epoch: 11.32% (566/5000)\tBatch: 100.00% (20/20)\tLoss: 956.348267\n",
      "***Validation Results***\tLoss: 292.2307,\tAccuracy: 49.45% (4945/10000)\n",
      "\n",
      "Training Epoch: 11.34% (567/5000)\tBatch: 100.00% (20/20)\tLoss: 1026.979004\n",
      "***Validation Results***\tLoss: 361.2080,\tAccuracy: 46.32% (4632/10000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_epoch = 5000, log_per_epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
