{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "import csv\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDateStr(csv_dict, idx):\n",
    "    OutStr = ''\n",
    "    for key in date_rel_dict:\n",
    "        OutStr += str(csv_dict[key][idx])+'_'\n",
    "    \n",
    "    return OutStr[:-1]\n",
    "\n",
    "date_rel_dict = {'arrival_date_year':True, 'arrival_date_month':True, 'arrival_date_day_of_month':True}\n",
    "\n",
    "def GetIdxDict(fn):\n",
    "    t_dict = pd.read_csv(fn)\n",
    "    dict_date_to_idx = {}\n",
    "    data_cnt = len(t_dict['arrival_date_year'])\n",
    "    for i in range(data_cnt): \n",
    "        date_str = GetDateStr(t_dict, i)\n",
    "        if dict_date_to_idx.get(date_str) == None:\n",
    "            dict_date_to_idx[date_str] = []\n",
    "        dict_date_to_idx[date_str].append(i)\n",
    "        \n",
    "    return dict_date_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict = GetIdxDict('data/preprocessed/train_processed.csv')\n",
    "test_dict = GetIdxDict('data/preprocessed/test_processed.csv')\n",
    "with open('data/preprocessed/test_prep.yaml', 'w') as outfile:\n",
    "    yaml.dump(test_dict, outfile, default_flow_style=False)\n",
    "    \n",
    "with open('data/preprocessed/train_prep.yaml', 'w') as outfile:\n",
    "    yaml.dump(train_dict, outfile, default_flow_style=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcs\n",
    "def read_file(fn):\n",
    "    with open(fn, mode='r') as test:\n",
    "        reader = csv.reader(test)\n",
    "        rowList = [row[1:] for row in reader]\n",
    "        header = rowList.pop(0)\n",
    "        return header\n",
    "    \n",
    "month_dict = {'January':1, 'February':2, 'March':3, 'April':4, 'May':5 ,'June':6,\n",
    "              'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\n",
    "\n",
    "date_rel_dict = {'arrival_date_year':True, 'arrival_date_month':True, 'arrival_date_day_of_month':True}\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def GetDateStr(csv_dict, idx):\n",
    "    OutStr = ''\n",
    "    for key in date_rel_dict:\n",
    "        OutStr += str(csv_dict[key][idx])+'_'\n",
    "    \n",
    "    return OutStr[:-1]\n",
    "\n",
    "def DictIsFloat(dt):\n",
    "    for key in dt:\n",
    "        if not isfloat(key):\n",
    "            return False\n",
    "    return True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel 2\n",
      "meal 5\n",
      "country 178\n",
      "market_segment 8\n",
      "distribution_channel 5\n",
      "reserved_room_type 10\n",
      "assigned_room_type 12\n",
      "deposit_type 3\n",
      "customer_type 4\n",
      "Successfully writen\n",
      "Successfully writen\n"
     ]
    }
   ],
   "source": [
    "train_dict = pd.read_csv('data/train.csv').fillna(-1)\n",
    "test_dict = pd.read_csv('data/test.csv').fillna(-1)\n",
    "header = read_file('data/test.csv')\n",
    "header = [hd for hd in header if not date_rel_dict.get(hd)]\n",
    "float_header = [hd for hd in header if DictIsFloat(train_dict[hd])]\n",
    "nonfloat_header = [hd for hd in header if not DictIsFloat(train_dict[hd])]\n",
    "nonfloat_header_dict_dict = {}\n",
    "\n",
    "for hd in nonfloat_header:\n",
    "    sub_dict = {}\n",
    "    for mem in list(train_dict[hd])+list(test_dict[hd]):\n",
    "        if sub_dict.get(mem) == None:\n",
    "            sub_dict[mem] = len(sub_dict)\n",
    "    nonfloat_header_dict_dict[hd] = sub_dict\n",
    "\n",
    "#check sized for one-hot \n",
    "for key in nonfloat_header_dict_dict:\n",
    "    print(key, len(nonfloat_header_dict_dict[key]))\n",
    "    \n",
    "with open('data/preprocessed/feature_encodings.yaml', 'w') as outfile:\n",
    "    yaml.dump(nonfloat_header_dict_dict, outfile, default_flow_style=False)\n",
    "    \n",
    "for key in date_rel_dict:\n",
    "    float_header.append(key)\n",
    "\n",
    "train_dict['arrival_date_month'] = list([month_dict[month] for month in list(train_dict['arrival_date_month'])])\n",
    "test_dict['arrival_date_month'] = list([month_dict[month] for month in list(test_dict['arrival_date_month'])])\n",
    "\n",
    "test, train = [], []\n",
    "for hd in nonfloat_header:\n",
    "    tmp = []\n",
    "    for mem in test_dict[hd]:\n",
    "        encoded = nonfloat_header_dict_dict[hd][mem]\n",
    "        tmp.append(encoded)\n",
    "    test.append(tmp)\n",
    "    \n",
    "    tmp = []\n",
    "    for mem in train_dict[hd]:\n",
    "        encoded = nonfloat_header_dict_dict[hd][mem]\n",
    "        tmp.append(encoded)\n",
    "    train.append(tmp)\n",
    "    \n",
    "for hd in float_header:\n",
    "    tmp = []\n",
    "    for mem in test_dict[hd]:\n",
    "        tmp.append(mem)\n",
    "    test.append(tmp)\n",
    "    \n",
    "    tmp = []\n",
    "    for mem in train_dict[hd]:\n",
    "        tmp.append(mem)\n",
    "    train.append(tmp)\n",
    "    \n",
    "with open('data/preprocessed/test.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = nonfloat_header+float_header\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    rowDict = {}\n",
    "    for i in range(len(test[0])):\n",
    "        for idx, fn in enumerate(fieldnames):\n",
    "            rowDict[fn] = test[idx][i]\n",
    "        writer.writerow(rowDict)\n",
    "print('Successfully writen')\n",
    "\n",
    "with open('data/preprocessed/train.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = nonfloat_header+float_header\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    rowDict = {}\n",
    "    for i in range(len(train[0])):\n",
    "        for idx, fn in enumerate(fieldnames):\n",
    "            rowDict[fn] = train[idx][i]\n",
    "        writer.writerow(rowDict)\n",
    "print('Successfully writen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/preprocessed/labels.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['adr', 'is_canceled']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    rowDict = {}\n",
    "    for i in range(len(train[0])):\n",
    "        for fn in fieldnames:\n",
    "            rowDict[fn] = train[idx][i]\n",
    "        writer.writerow(rowDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding completed\n",
      "\n",
      "Using the Following Notation: \n",
      " {'Check-Out, 0': 0, 'Check-Out, 1': 1, 'Canceled, 0': 2, 'Canceled, 1': 3, 'No-Show, 0': 4, 'No-Show, 1': 5}\n"
     ]
    }
   ],
   "source": [
    "#encode non float scripts with one-hot vec and show encoding dictionary\n",
    "tensors = prep.GetFeatureVectorsAndLabels(fnTrain = 'data/train.csv', fnTest = 'data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_data_tensor.pt \t torch.Size([91531, 258])\n",
      "data/test_data_tensor.pt \t torch.Size([27859, 258])\n",
      "data/train_label_tensor_adr.pt \t torch.Size([91531, 1])\n",
      "data/train_label_tensor_rev.pt \t torch.Size([91531, 1])\n"
     ]
    }
   ],
   "source": [
    "#save tensors\n",
    "fnList = ['train_data_tensor.pt', 'test_data_tensor.pt', 'train_label_tensor_adr.pt', 'train_label_tensor_rev.pt']\n",
    "for tensor, fn in zip(tensors, fnList):\n",
    "    torch.save(tensor, os.path.join('data', fn))\n",
    "    \n",
    "#reload to check if saving succeeded\n",
    "for fn in fnList:\n",
    "    fn = os.path.join('data', fn)\n",
    "    print(fn, '\\t', torch.load(fn).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test set from train set for validations\n",
    "train_data_tensor, _,  train_label_tensor_adr, train_label_tensor_rev = tensors\n",
    "tensors = prep.RandomSplit(train_data_tensor, train_label_tensor_adr, train_label_tensor_rev, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/data.pt \t torch.Size([10000, 258])\n",
      "data/train/data.pt \t torch.Size([81531, 258])\n",
      "data/test/adr.pt \t torch.Size([10000, 1])\n",
      "data/train/adr.pt \t torch.Size([81531, 1])\n",
      "data/test/rev.pt \t torch.Size([10000, 1])\n",
      "data/train/rev.pt \t torch.Size([81531, 1])\n"
     ]
    }
   ],
   "source": [
    "#save tensors\n",
    "fnList = ['test/data.pt', 'train/data.pt', 'test/adr.pt', 'train/adr.pt', 'test/rev.pt', 'train/rev.pt']\n",
    "for tensor, fn in zip(tensors, fnList):\n",
    "    torch.save(tensor, os.path.join('data', fn))\n",
    "\n",
    "#reload to check if saving succeeded   \n",
    "for fn in fnList:\n",
    "    fn = os.path.join('data', fn)\n",
    "    print(fn, '\\t', torch.load(fn).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataSet(fnTrain, fnTest):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
